{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73acda0b",
   "metadata": {},
   "source": [
    "\n",
    "# Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import poppy\n",
    "import astropy.units as u\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from astropy.stats import sigma_clip\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from scipy.optimize import curve_fit\n",
    "import photutils\n",
    "import time\n",
    "import datetime as dt\n",
    "from scipy import fftpack\n",
    "import nbformat\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from turbustat.statistics import PowerSpectrum\n",
    "from scipy.signal import butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from astropy.io.fits import Header\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import csv\n",
    "import gc\n",
    "from photutils.aperture import aperture_photometry, CircularAperture, CircularAnnulus\n",
    "from photutils.aperture import ApertureStats\n",
    "from astropy.table import Table\n",
    "\n",
    "# Colormap\n",
    "dark_yellow = [ '#003f5c', '#2f4b7c', '#665191', '#a05195', '#d45087', '#f95d6a', '#ff7c43', '#ffa600']\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"DarkYellow\", dark_yellow)\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed680f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style=\"color:yellow; font-size:40px;\">Variabili in input</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a17189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffraction limit in arcseconds and pixels:  0.17504418560439558 16.05909959673354\n",
      "Expected speckle size in arcseconds and pixels:  0.07035025819440659 6.45415212792721\n"
     ]
    }
   ],
   "source": [
    "############### PER SPECKLE FIT ###################################\n",
    "speckle_thresholds=[3000, 4000, 12000]  # da cambiare a seconda dei target usati\n",
    "speckle_threshold=7000 #1100 #7000 #9500 #8000 #9000 #6500 #9000\n",
    "# Plate scale arcseconds/pixels\n",
    "plate_scales=[0.0377,  0.0109, 0.012]  #plate cslae di gennaio, febbraio e marzo rispettivamente\n",
    "plate_scale = 0.0109 # 0.012#4-MARZO #0.0109 #FEBBRAIO# 0.0377 #0.0244*2 #0.0376*2 #0.0268 marzo #0.0244 febb #0.0376 #\n",
    "# Diffraction limit of the telescope\n",
    "aperture = 1.82                                                     # Aperture of the telescope (in meters)\n",
    "wavelength = 633e-9 #700e-9                                                 # Reference wavelenght (in meters) \n",
    "diffraction_limit_radians = 2*1.22 * wavelength / aperture          # Diameter of the Airy disk\n",
    "diffraction_limit_arcseconds = diffraction_limit_radians * 206265\n",
    "expected_speckle_size_radians = 0.8038 *(1.22 * wavelength / aperture)\n",
    "expected_speckle_size = expected_speckle_size_radians * 206265  \n",
    "expected_speckle_size_pixels = expected_speckle_size / plate_scale\n",
    "# Radius use for the fit of the speckles (in pixels)\n",
    "radius=int((diffraction_limit_arcseconds/plate_scale)/2)  # raggio della zona del fit attorno alle speckle (Diametro = disco di airy)\n",
    "check_radius = int((diffraction_limit_arcseconds*0.5)/plate_scale) # raggio della zona di controllo attorno alle speckle (Diametro = disco di airy)\n",
    "mindist = 5 #distanza dimina in pixel tra 2 speckle (per evitare che la stessa speckle venga contata più volte)\n",
    "print(\"Diffraction limit in arcseconds and pixels: \",diffraction_limit_arcseconds, diffraction_limit_arcseconds/plate_scale)\n",
    "print(\"Expected speckle size in arcseconds and pixels: \", expected_speckle_size, expected_speckle_size_pixels)\n",
    "\n",
    "###########    PER PSD   ##################################################\n",
    "ordine = 5 #  NON OLTRE 6\n",
    "imagenumber = 300 #500\n",
    "stacked = False  # Fa PSD di più immagini sommate (3 al momento)\n",
    "nstack = 3 # immagini da sommare se si vuole usare il Power specrum di immagini sommate\n",
    "lowcut_pix = 14#15#7  #max dimension in pixel\n",
    "highcut_pix = 4#9#2.1  #min dimension in pixel\n",
    "lowcut= 1/lowcut_pix \n",
    "highcut = 1/highcut_pix\n",
    "crop_size = 2000   # FORMATO IMMAGINE FINALE: N pixel X N pixel (dimiuisce la dimensione dell'immagine per velocizzare i calcoli)\n",
    "frequency_range = 0.15    # range per trovare il picco delle spckle (centrato nella frequenza delle speckle teorica)\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7e3e3",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-size: 1em;\"> Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b20887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcProcessTime(starttime, cur_iter, max_iter):\n",
    "\n",
    "    telapsed = time.time() - starttime\n",
    "    testimated = (telapsed/cur_iter)*(max_iter)\n",
    "    finishtime = starttime + testimated\n",
    "    finishtime = dt.datetime.fromtimestamp(finishtime).strftime(\"%H:%M:%S\")\n",
    "    lefttime = testimated-telapsed \n",
    "\n",
    "    return (int(telapsed), int(lefttime), finishtime)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale):\n",
    "    fwhm_results = []\n",
    "    centers = []\n",
    "    \n",
    "    for speckle in filtered_speckles:\n",
    "        y_ref, x_ref = speckle  \n",
    "        masked_data = data.copy() \n",
    "        y, x = np.mgrid[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data = masked_data[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data[masked_data < 0] = 0 \n",
    "        \n",
    "        ###########################################################################\n",
    "        #Se attivo, fa il fit in una regione circolare\n",
    "        distance = np.sqrt((x - x_ref)**2 + (y - y_ref)**2)\n",
    "        circular_mask = distance <= radius\n",
    "        masked_data = np.where(circular_mask, masked_data, 0)\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Set border pixels to 0\n",
    "        masked_data[0, :] = 0\n",
    "        masked_data[-1, :] = 0\n",
    "        masked_data[:, 0] = 0\n",
    "        masked_data[:, -1] = 0\n",
    "\n",
    "        gaussian_model = models.Gaussian2D(amplitude=masked_data.max(), x_mean=x_ref, y_mean=y_ref, x_stddev=0.5, y_stddev=0.5)\n",
    "        gaussian_model.amplitude.min = speckle_threshold\n",
    "        gaussian_model.amplitude.max = masked_data.max()\n",
    "        gaussian_model.x_mean.min = x_ref - 5   # METTERE A 1 PER LE SPECKLE A 3X\n",
    "        gaussian_model.x_mean.max = x_ref + 5\n",
    "        gaussian_model.y_mean.min = y_ref - 5\n",
    "        gaussian_model.y_mean.max = y_ref + 5\n",
    "\n",
    "        fitter = fitting.LevMarLSQFitter()\n",
    "        fitted_model = fitter(gaussian_model, x, y, masked_data)\n",
    "\n",
    "        fwhm_x = 2.355 * fitted_model.x_stddev.value * plate_scale\n",
    "        fwhm_y = 2.355 * fitted_model.y_stddev.value * plate_scale\n",
    "        fwhm_results.append((fwhm_y, fwhm_x))\n",
    "        centers.append((fitted_model.y_mean.value, fitted_model.x_mean.value))\n",
    "\n",
    "    return np.array(fwhm_results), np.array(centers)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def gaussiana(bins, media, sigma):\n",
    "\tx = np.zeros(len(bins)-1)\n",
    "\tfor i in range(len(x)):\n",
    "\t\tx[i] = (bins[i]+bins[i+1])/2\n",
    "\ty = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-(x-media)**2/(2*sigma**2))\n",
    "\treturn x, y\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def calculate_2dft(input):\n",
    "    ft = np.fft.ifftshift(input)\n",
    "    ft = np.fft.fft2(ft)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def butterworth_2d_bandpass(image, lowcut, highcut, order=5):\n",
    "    ny, nx = image.shape\n",
    "    y, x = np.ogrid[:ny, :nx]\n",
    "    cy, cx = ny // 2, nx // 2\n",
    "    # Create normalized radius grid (distance from center)\n",
    "    radius = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    radius /= np.max(radius)  # Normalize to [0, 1]\n",
    "    # Normalize lowcut/highcut to [0, 1] as fraction of Nyquist\n",
    "    low = lowcut * 2\n",
    "    high = highcut * 2\n",
    "    # Butterworth bandpass formula\n",
    "    def butterworth(freq, cutoff, n):\n",
    "        return 1 / (1 + (freq / cutoff)**(2 * n))\n",
    "    # Bandpass = Highpass * Lowpass\n",
    "    lowpass = butterworth(radius, high, order)\n",
    "    highpass = 1 - butterworth(radius, low, order)\n",
    "    bandpass_mask = lowpass * highpass\n",
    "    # Apply filter in frequency domain\n",
    "    fft_image = np.fft.fft2(image)\n",
    "    fft_shifted = np.fft.fftshift(fft_image)\n",
    "    filtered_fft = fft_shifted * bandpass_mask\n",
    "    filtered_image = np.fft.ifft2(np.fft.ifftshift(filtered_fft)).real\n",
    "    return filtered_image, bandpass_mask\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def crop_center(image, size):\n",
    "    \"\"\"\n",
    "    Crop a square region of given size around the image center.\n",
    "\n",
    "    \"\"\"\n",
    "    ny, nx = image.shape\n",
    "    cx, cy = nx // 2, ny // 2\n",
    "    half = size // 2\n",
    "    x_min = cx - half\n",
    "    x_max = cx + half\n",
    "    y_min = cy - half\n",
    "    y_max = cy + half\n",
    "    return image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def plot_psd_peak(freqs, ps1D, largest_peak_freq, frequency_range, expected_speckle_size, plate_scale):\n",
    "    zoom_range = (largest_peak_freq - frequency_range / 2, largest_peak_freq + frequency_range / 2)\n",
    "    zoom_indices = (freqs >= zoom_range[0]) & (freqs <= zoom_range[1])\n",
    "    zoom_freqs = freqs[zoom_indices]\n",
    "    zoom_power = ps1D[zoom_indices]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.loglog(zoom_freqs, zoom_power, label='Zoomed Power Spectrum')  # Emphasize the zoomed region\n",
    "    plt.axvline(x=largest_peak_freq, color='red', linestyle='--', label=f'Peak: {largest_peak_freq:.4f} pix⁻¹')\n",
    "    plt.axvline(x=1/(expected_speckle_size/plate_scale), color='magenta', linestyle='--', label='Expected Speckle Size')\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.xlabel(\"Spatial Frequency [pix⁻¹]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.grid(True, which=\"both\", linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "##################################################################################\n",
    "######################################################################################\n",
    "def find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range):\n",
    "    \"\"\"\n",
    "    frequency_range : Range around the expected speckle frequency to search for the peak.\n",
    "    largest_peak_freq : Frequency with the largest power within the specified range.\n",
    "    largest_peak_power : Largest power within the specified frequency range.\n",
    "    \"\"\"\n",
    "    expected_speckle_frequency = 1 / expected_speckle_size_pixels\n",
    "    lower_freq = expected_speckle_frequency - frequency_range / 2\n",
    "    upper_freq = expected_speckle_frequency + frequency_range / 2\n",
    "    #print(expected_speckle_size_pixels,expected_speckle_frequency, lower_freq, upper_freq)\n",
    "    peak_indices = (freqs >= lower_freq) & (freqs <= upper_freq)\n",
    "\n",
    "    if not any(peak_indices):\n",
    "        print(\"No frequencies selected within the specified range.\")\n",
    "        return None, None\n",
    "\n",
    "    selected_freqs = freqs[peak_indices]\n",
    "    selected_power = ps1D[peak_indices]\n",
    "    largest_peak_index = np.argmax(selected_power)\n",
    "    largest_peak_freq = selected_freqs[largest_peak_index]\n",
    "    largest_peak_power = selected_power[largest_peak_index]\n",
    "    \n",
    "    return largest_peak_freq, largest_peak_power\n",
    "#################################################################################\n",
    "##################################################################################\n",
    "def scale_and_speckle_selector(plate_scales, speckle_thresholds, file):\n",
    "    if 'arcturus' in file:\n",
    "        speckle_threshold = speckle_thresholds[1]\n",
    "    if 'castor' in file:\n",
    "        speckle_threshold = speckle_thresholds[0]\n",
    "    if 'aldebaran' in file:\n",
    "        speckle_threshold = speckle_thresholds[2]   \n",
    "    if 'febbraio' in file:\n",
    "        plate_scale = plate_scales[1]\n",
    "    if 'marzo' in file:\n",
    "        plate_scale = plate_scales[2]\n",
    "    print(\"Plate scale in arcseconds/pixel: \", plate_scale)\n",
    "    print(\"Speckle threshold: \", speckle_threshold)\n",
    "    return plate_scale, speckle_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ffaf9",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-size: 1em;\"> Codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tifffile:<tifffile.TiffFile 'aldebaran_marzo_40ms_elev30.tif'> MMStack file name is invalid\n",
      "WARNING:tifffile:<tifffile.TiffFile 'aldebaran_marzo_40ms_elev30.tif'> MMStack series is missing files. Returning subset (1, 511, 1, 1) of (1, 5000, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files in the folder\n",
      "Loaded data from aldebaran_marzo_40ms_elev30.tif\n",
      "Analysing aldebaran_marzo_40ms_elev30.tif...\n",
      "Plate scale in arcseconds/pixel:  0.012\n",
      "Speckle threshold:  12000\n",
      "time elapsed: 20 s, time left: 20 s, estimated finish time: 16:50:44\n",
      "Speckles fit done\n",
      "Power Spectra ofaldebaran_marzo_40ms_elev30.tif...\n",
      "processing image  1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\turbustat\\statistics\\base_statistic.py:66: UserWarning: Header missing beam information.\n",
      "  warn(\"Header missing beam information.\")\n",
      "c:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak frequencies: [0.11716766784452298]\n",
      "peak powers: [7436.192644522007]\n",
      "Power Spectrum of aldebaran_marzo_40ms_elev30.tif done\n",
      "processing image  1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\turbustat\\statistics\\base_statistic.py:66: UserWarning: Header missing beam information.\n",
      "  warn(\"Header missing beam information.\")\n",
      "c:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak frequencies: [0.11716766784452298, 0.11716766784452298]\n",
      "peak powers: [7436.192644522007, 7436.192644522007]\n",
      "Power Spectrum of aldebaran_marzo_40ms_elev30.tif done\n",
      "aaaaaaaaaaaaaaaaaaaaaaa [0.12322746398002773, 0.11668638779413026] 2\n",
      "All results saved to FITS table: outputs/results_aldebaran_marzo_40ms_elev30.tif.fits\n",
      "All results saved to CSV file: outputs/results_aldebaran_marzo_40ms_elev30.tif.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tifffile:<tifffile.TiffFile 'arcturus_febbraio_elev60.tif'> MMStack file name is invalid\n",
      "WARNING:tifffile:<tifffile.TiffFile 'arcturus_febbraio_elev60.tif'> MMStack series is missing files. Returning subset (1, 8136, 1, 1) of (1, 10000, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files in the folder\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4556\\2200114126.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#immagini_list = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mFound \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m files in the folder\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimmagini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#immagini_list.append(immagini)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mLoaded data from \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf'\u001b[0m\u001b[1;33mAnalysing \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1252\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mselection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mzarr_selection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m                 return tif.asarray(\n\u001b[0m\u001b[0;32m   1257\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m                     \u001b[0mseries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, series, level, squeeze, out, maxworkers, buffersize)\u001b[0m\n\u001b[0;32m   4554\u001b[0m             result = page0.asarray(\n\u001b[0;32m   4555\u001b[0m                 \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffersize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4556\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4558\u001b[1;33m             result = stack_pages(\n\u001b[0m\u001b[0;32m   4559\u001b[0m                 \u001b[0mpages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffersize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4560\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pages, tiled, lock, maxworkers, out, **kwargs)\u001b[0m\n\u001b[0;32m  23323\u001b[0m                 \u001b[0mfilecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmaxworkers\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23326\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 23327\u001b[1;33m                 \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  23328\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23329\u001b[0m             \u001b[0mpage0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m  \u001b[1;31m# init TiffPage.decode function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23330\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(page, index, out, filecache, kwargs)\u001b[0m\n\u001b[0;32m  23318\u001b[0m         \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23319\u001b[0m             \u001b[1;31m# read, decode, and copy page data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  23321\u001b[0m                 \u001b[0mfilecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 23322\u001b[1;33m                 \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  23323\u001b[0m                 \u001b[0mfilecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilehandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m  10276\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10277\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m`\u001b[0m\u001b[0mTiffPage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10279\u001b[0m         \"\"\"\n\u001b[1;32m> 10280\u001b[1;33m         return TiffPage.asarray(\n\u001b[0m\u001b[0;32m  10281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10282\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, out, squeeze, lock, maxworkers, buffersize)\u001b[0m\n\u001b[0;32m   8805\u001b[0m                     warnings.warn(\n\u001b[0;32m   8806\u001b[0m                         \u001b[1;33mf'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m!\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m reading array from closed file\u001b[0m\u001b[1;33m'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8807\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8808\u001b[0m                     \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8809\u001b[1;33m                 \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataoffsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8810\u001b[0m                 result = fh.read_array(\n\u001b[0;32m   8811\u001b[0m                     \u001b[0mkeyframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkeyframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8812\u001b[0m                     \u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\buonc\\anaconda3\\envs\\donut\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, offset, whence)\u001b[0m\n\u001b[0;32m  14860\u001b[0m                 return (\n\u001b[0;32m  14861\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14862\u001b[0m                     \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14863\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 14864\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\"\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "#immagini_list = []\n",
    "for file in file_list: \n",
    "    print(f\"Found {len(file_list)} files in the folder\")\n",
    "    file_name = os.path.basename(file)\n",
    "    immagini = tifffile.imread(file)[:2]\n",
    "    #immagini_list.append(immagini)\n",
    "    print(f\"Loaded data from {file_name}\")\n",
    "    print(f'Analysing {file_name}...')\n",
    "    \n",
    "    scale_and_speckle_selector(plate_scales, speckle_thresholds, file_name)\n",
    "    diffraction_limit_radians = 2*1.22 * wavelength / aperture          # Diameter of the Airy disk\n",
    "    diffraction_limit_arcseconds = diffraction_limit_radians * 206265\n",
    "    expected_speckle_size_radians = 0.8038 *(1.22 * wavelength / aperture)\n",
    "    expected_speckle_size = expected_speckle_size_radians * 206265  \n",
    "    expected_speckle_size_pixels = expected_speckle_size / plate_scale\n",
    "    # Radius use for the fit of the speckles (in pixels)\n",
    "    radius=int((diffraction_limit_arcseconds/plate_scale)/2)  # raggio della zona del fit attorno alle speckle (Diametro = disco di airy)\n",
    "    check_radius = int((diffraction_limit_arcseconds*0.5)/plate_scale) # raggio della zona di controllo attorno alle speckle (Diametro = disco di airy)\n",
    "    #mindist = 5 #distanza dimina in pixel tra 2 speckle (per evitare che la stessa speckle venga contata più volte)\n",
    "    \n",
    "    ############# SPECKLE FIT ##########################################################\n",
    "    \n",
    "    start = time.time()\n",
    "    fwhm_single_image = []\n",
    "    fwhm_mean_all = []\n",
    "    fwhm_median_all = []\n",
    "    fwhm_std_all = []\n",
    "    centroid_all = []   # first coordinate in the array is the Y\n",
    "    rms_all = []        # first coordinate in the array is the Y\n",
    "    fwhm_mean_filtered_all = []\n",
    "    fwhm_median_filtered_all = []\n",
    "    fwhm_std_filtered_all = []\n",
    "    rms_filtered_all = []\n",
    "    centroid_filtered_all = []\n",
    "    ellipticity_mean_all=[]\n",
    "\n",
    "    for imagenumber in range(len(immagini)):\n",
    "        data_raw = immagini[imagenumber]\n",
    "        data_clean = data_raw\n",
    "        poisson_error = np.sqrt(data_raw)\n",
    "        background_level = np.median(data_raw)\n",
    "        background_error = np.sqrt(background_level)\n",
    "        noise = np.sqrt(np.mean(poisson_error**2) + background_error**2)\n",
    "        background_estimate = data_raw - noise\n",
    "        background_estimate[background_estimate < 0] = 0\n",
    "        data = data_raw - background_level\n",
    "        data[data < 0] = 0\n",
    "\n",
    "        ###########################     SOLO PER 10KHZ ################################################\n",
    "        #center_y, center_x = data.shape[0] // 2, data.shape[1] // 2\n",
    "        #search_radius = 80  ###per speckle a 3x\n",
    "        #y, x = np.ogrid[:data.shape[0], :data.shape[1]]\n",
    "        #mask = (x - center_x)**2 + (y - center_y)**2 <= search_radius**2\n",
    "        #speckle_coords = np.column_stack(np.where((data > speckle_threshold) & mask))\n",
    "        ################################################################################################\n",
    "        # QUANDO NON ATTIVO SPECKLE A 10KHZ\n",
    "        speckle_coords = np.column_stack(np.where(data > speckle_threshold))\n",
    "        real_speckles = []\n",
    "\n",
    "        for coord in speckle_coords:\n",
    "            y, x = coord\n",
    "            max_count = data[y, x]\n",
    "            speckle = coord\n",
    "            # Check the surrounding pixels within the radius\n",
    "            for dy in range(-check_radius, check_radius + 1):\n",
    "                for dx in range(-check_radius, check_radius + 1):\n",
    "                    ny, nx = y + dy, x + dx\n",
    "                    if 0 <= ny < data.shape[0] and 0 <= nx < data.shape[1]:\n",
    "                        if data[ny, nx] > max_count:\n",
    "                            max_count = data[ny, nx]\n",
    "                            speckle = [ny, nx]           \n",
    "            if not any(np.array_equal(speckle, x) for x in real_speckles):\n",
    "                real_speckles.append(speckle)\n",
    "                \n",
    "        real_speckles = np.array(real_speckles)\n",
    "        filtered_speckles = []\n",
    "                \n",
    "        for speckle in real_speckles:\n",
    "            y, x = speckle\n",
    "            max_count = data[y, x]\n",
    "            keep_speckle = True\n",
    "            # Check for speckles that are closer than N pixels\n",
    "            for other_speckle in filtered_speckles:\n",
    "                distance = np.sqrt((other_speckle[0] - y)**2 + (other_speckle[1] - x)**2)\n",
    "                if distance < mindist:   # change here to change the radius (in pixels)\n",
    "                    if data[other_speckle[0], other_speckle[1]] > max_count:\n",
    "                        keep_speckle = False\n",
    "                    else:\n",
    "                        filtered_speckles = [fs for fs in filtered_speckles if not np.array_equal(fs, other_speckle)]\n",
    "            if keep_speckle:\n",
    "                filtered_speckles.append([y, x])\n",
    "\n",
    "        filtered_speckles = np.array(filtered_speckles)\n",
    "    ###################################à SOLO PER 10KHZ ##############################################  \n",
    "        # Calculate the barycenter of the filtered speckles\n",
    "        #barycenter_x = filtered_speckles[:, 1].mean()\n",
    "        #barycenter_y = filtered_speckles[:, 0].mean()\n",
    "    # Define a maximum distance from the barycenter to consider a speckle as valid\n",
    "        #max_distance = 50  \n",
    "        #distances = np.sqrt((filtered_speckles[:, 1] - barycenter_x)**2 + (filtered_speckles[:, 0] - barycenter_y)**2)\n",
    "        #filtered_speckles = filtered_speckles[distances <= max_distance] \n",
    "    #############################################################################\n",
    "\n",
    "       \n",
    "        fwhm_single_image, centers = fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale)\n",
    "\n",
    "\n",
    "        ellipticity_single_image = 1 - np.minimum(fwhm_single_image[:, 0], fwhm_single_image[:, 1]) / np.maximum(fwhm_single_image[:, 0], fwhm_single_image[:, 1])\n",
    "\n",
    "        #tutto con indice 1 perché si sta facendo statistica solo sulla X\n",
    "        fwhm_x_clipped = sigma_clip(fwhm_single_image[:, 1], sigma=3, maxiters=1)  # o 1 a 3 sigma o 3 a 3.5 sigma\n",
    "        fwhm_x_tot_clean = fwhm_single_image[~fwhm_x_clipped.mask]\n",
    "        mean_clipped_fwhm = np.mean(fwhm_x_tot_clean[:,1])\n",
    "        median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean[:,1])\n",
    "        std_clipped_fwhm = np.std(fwhm_x_tot_clean[:,1]) \n",
    "        centroid = (np.mean(centers[:,0]), np.mean(centers[:,1])) \n",
    "        rms = (np.sqrt(np.mean((centers[:,0] - centroid[0])**2)), np.sqrt(np.mean((centers[:,1] - centroid[1])**2))) \n",
    "        # mean_clipped_fwhm = np.mean(fwhm_x_tot_clean)\n",
    "        # median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean)\n",
    "        # std_clipped_fwhm = np.std(fwhm_x_tot_clean)\n",
    "\n",
    "        # Store results for all speckles\n",
    "        fwhm_mean_all.append(mean_clipped_fwhm)\n",
    "        fwhm_median_all.append(median_clipped_fwhm)\n",
    "        fwhm_std_all.append(std_clipped_fwhm)\n",
    "        rms_all.append(rms)\n",
    "        centroid_all.append(centroid)\n",
    "        ellipticity_mean_all.append(np.mean(ellipticity_single_image))\n",
    "        \n",
    "        if imagenumber % 500 == 0:\n",
    "            prstime = calcProcessTime(start, imagenumber +1 ,len(immagini))\n",
    "            print(\"time elapsed: %s s, time left: %s s, estimated finish time: %s\"%prstime)\n",
    "            \n",
    "    print('Speckles fit done')\n",
    "\n",
    "######################## SPECKLE PSD ######################\n",
    "\n",
    "    print(f'Power Spectra of{file_name}...')\n",
    "    \n",
    "    header = Header()\n",
    "    header['CDELT1'] = 1.0\n",
    "    header['CDELT2'] = 1.0\n",
    "    peak_frequencies = []\n",
    "    peak_powers = []\n",
    "\n",
    "    for image in range(len(immagini)):\n",
    "        print(\"processing image \", image ,'/', len(immagini))\n",
    "        largest_peak_freq = 0\n",
    "        largest_peak_power = 0\n",
    "        \n",
    "        #if stacked and i + nstack <= len(immagini):\n",
    "        #    data = np.sum(immagini[i:i + 3], axis=0)\n",
    "        #else:\n",
    "        #    data = image\n",
    "        image_cropped = crop_center(data, crop_size)\n",
    "        data = image_cropped.copy()\n",
    "        background_level = np.median(data)\n",
    "        data = data - background_level\n",
    "        data[data < 0] = 0\n",
    "        image = data.copy()\n",
    "\n",
    "        # Apply 2D Butterworth bandpass\n",
    "        filtered_image, mask = butterworth_2d_bandpass(image, lowcut, highcut, ordine)\n",
    "        # Normalize filtered image\n",
    "        filtered_image = np.nan_to_num(filtered_image, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        filtered_image[filtered_image < 0] = 0\n",
    "        filtered_image /= (np.max(filtered_image) + 1e-8)\n",
    "\n",
    "        # Compute power spectrum\n",
    "        pspec_filtered = PowerSpectrum(filtered_image, header=header, distance=1 * u.pc)\n",
    "        pspec_filtered.run(verbose=False, xunit=u.pix**-1)\n",
    "        \n",
    "        freqs = pspec_filtered.freqs.value\n",
    "        ps1D = pspec_filtered.ps1D\n",
    "        largest_peak_freq, largest_peak_power = find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range)\n",
    "        \n",
    "        peak_frequencies.append(largest_peak_freq)\n",
    "        peak_powers.append(largest_peak_power)\n",
    "        print('peak frequencies:', peak_frequencies)\n",
    "        print('peak powers:', peak_powers)\n",
    "\n",
    "        if largest_peak_freq == 0 and largest_peak_power == 0:\n",
    "             print(\"Could not find any peaks within the specified frequency range.\")\n",
    "        print(f'Power Spectrum of {file_name} done')\n",
    "\n",
    "\n",
    "############################# SALVATAGGIO RISULTATI ########################################\n",
    "#######################################################################################     \n",
    "    # # FITS file\n",
    "    # primary_hdu = fits.PrimaryHDU()\n",
    "    # fwhm_mean_hdu = fits.ImageHDU(data=np.array(fwhm_mean_all), name='FWHM_MEAN')\n",
    "    # fwhm_median_hdu = fits.ImageHDU(data=np.array(fwhm_median_all), name='FWHM_MEDIAN')\n",
    "    # fwhm_std_hdu = fits.ImageHDU(data=np.array(fwhm_std_all), name='FWHM_STD')\n",
    "    # centroid_hdu = fits.ImageHDU(data=np.array(centroid_all), name='CENTROID')\n",
    "    # rms_hdu = fits.ImageHDU(data=np.array(rms_all), name='RMS')\n",
    "    # ellipticity_means_hdu = fits.ImageHDU(data=np.array(ellipticity_mean_all), name='MEAN_ELLIPTICITY')\n",
    "    # peak_frequencies_hdu = fits.ImageHDU(data=np.array(peak_frequencies), name='PEAK_FREQUENCIES')\n",
    "    # peak_powers_hdu = fits.ImageHDU(data=np.array(peak_powers), name='PEAK_POWERS')\n",
    "    # hdul = fits.HDUList([\n",
    "    #     primary_hdu, fwhm_mean_hdu, fwhm_median_hdu, fwhm_std_hdu, \n",
    "    #     centroid_hdu, rms_hdu, ellipticity_means_hdu, \n",
    "    #     peak_frequencies_hdu, peak_powers_hdu\n",
    "    # ])\n",
    "    # output_fits_file = f'outputs/results_{file_name}.fits'\n",
    "    # hdul.writeto(output_fits_file, overwrite=True)\n",
    "    # hdul.close()\n",
    "    print('aaaaaaaaaaaaaaaaaaaaaaa', fwhm_mean_all, len(immagini))\n",
    "\n",
    "    cent_x = [c[0] for c in centroid_all]\n",
    "    cent_y = [c[1] for c in centroid_all]\n",
    "    # Build table\n",
    "    N = len(fwhm_mean_all)\n",
    "    #ensure all lists are length N \n",
    "    tbl = Table({\n",
    "        'FWHM_MEAN':         np.array(fwhm_mean_all),\n",
    "        'FWHM_MEDIAN':       np.array(fwhm_median_all),\n",
    "        'FWHM_STD':          np.array(fwhm_std_all),\n",
    "        'CENTROID_X':        np.array(cent_x),\n",
    "        'CENTROID_Y':        np.array(cent_y),\n",
    "        'RMS_X':             np.array([r[0] for r in rms_all]),\n",
    "        'RMS_Y':             np.array([r[1] for r in rms_all]),\n",
    "        'MEAN_ELLIPTICITY':  np.array(ellipticity_mean_all),\n",
    "        'PEAK_FREQUENCY':    np.array(peak_frequencies),\n",
    "        'PEAK_POWER':        np.array(peak_powers),\n",
    "    })\n",
    "    output_fits_file = f'outputs/results_{file_name}.fits'\n",
    "    tbl.write(output_fits_file, format='fits', overwrite=True)\n",
    "    print(f\"All results saved to FITS table: {output_fits_file}\")\n",
    "\n",
    "    # CSV file\n",
    "    # output_csv_file = f'outputs/results_{file_name}.csv'\n",
    "    # with open(output_csv_file, mode='w', newline='') as file:\n",
    "    #     writer = csv.writer(file)\n",
    "    #     writer.writerow([\n",
    "    #         'FWHM_MEAN', 'FWHM_MEDIAN', 'FWHM_STD', \n",
    "    #         'CENTROID_X', 'CENTROID_Y', 'RMS_X', 'RMS_Y', \n",
    "    #         'MEAN_ELLIPTICITY', 'PEAK_FREQUENCY', 'PEAK_POWER'\n",
    "    #     ])\n",
    "    #     for mean, median, std, centroid, rms, ellipticity, freq, power in zip(\n",
    "    #         fwhm_mean_all, fwhm_median_all, fwhm_std_all, \n",
    "    #         centroid_all, rms_all, ellipticity_mean_all, \n",
    "    #         peak_frequencies, peak_powers\n",
    "    #     ):\n",
    "    #         writer.writerow([\n",
    "    #             mean, median, std, centroid[0], centroid[1], \n",
    "    #             rms[0], rms[1], ellipticity, freq, power\n",
    "    #         ])\n",
    "    # print(f\"All results saved to CSV file: {output_csv_file}\")\n",
    "\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    output_csv_file = f'outputs/results_{file_name}.csv'\n",
    "    with open(output_csv_file, 'w', newline='') as fh:\n",
    "        writer = csv.writer(fh)\n",
    "        writer.writerow([\n",
    "            'FWHM_MEAN','FWHM_MEDIAN','FWHM_STD',\n",
    "            'CENTROID_X','CENTROID_Y','RMS_X','RMS_Y',\n",
    "            'MEAN_ELLIPTICITY','PEAK_FREQUENCY','PEAK_POWER'\n",
    "        ])\n",
    "        N = len(fwhm_mean_all)\n",
    "        for i in range(N):\n",
    "            mean = fwhm_mean_all[i]\n",
    "            med  = fwhm_median_all[i] if i < len(fwhm_median_all) else np.nan\n",
    "            std  = fwhm_std_all[i]    if i < len(fwhm_std_all)    else np.nan\n",
    "            cx, cy = centroid_all[i]  if i < len(centroid_all)  else (np.nan, np.nan)\n",
    "            rx, ry = rms_all[i]       if i < len(rms_all)       else (np.nan, np.nan)\n",
    "            ell   = ellipticity_mean_all[i] if i < len(ellipticity_mean_all) else np.nan\n",
    "            freq  = peak_frequencies[i]     if i < len(peak_frequencies)     else np.nan\n",
    "            pw    = peak_powers[i]          if i < len(peak_powers)          else np.nan\n",
    "            writer.writerow([mean, med, std, cx, cy, rx, ry, ell, freq, pw])\n",
    "    print(f\"All results saved to CSV file: {output_csv_file}\")\n",
    "\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "       \n",
    "    del immagini\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e92286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column lengths: {'FWHM_MEAN': 2, 'FWHM_MEDIAN': 2, 'FWHM_STD': 2, 'CENTROID': 2, 'RMS': 2, 'MEAN_ELLIPTICITY': 2, 'PEAK_FREQUENCIES': 2, 'PEAK_POWERS': 2}\n",
      "0.11716766784452298 7436.192644522007 [0.11716766784452298, 0.11716766784452298] [7436.192644522007, 7436.192644522007]\n",
      "[0.1246675716533446, 0.11766614498834056]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your lists are in variables as shown\n",
    "lengths = {\n",
    "    'FWHM_MEAN': len(fwhm_mean_all),\n",
    "    'FWHM_MEDIAN': len(fwhm_median_all),\n",
    "    'FWHM_STD': len(fwhm_std_all),\n",
    "    'CENTROID': len(centroid_all),\n",
    "    'RMS': len(rms_all),\n",
    "    'MEAN_ELLIPTICITY': len(ellipticity_mean_all),\n",
    "    'PEAK_FREQUENCIES': len(peak_frequencies),\n",
    "    'PEAK_POWERS': len(peak_powers),\n",
    "}\n",
    "print(\"Column lengths:\", lengths)\n",
    "\n",
    "print(largest_peak_freq, largest_peak_power, peak_frequencies, peak_powers)\n",
    "print(fwhm_median_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138b2af",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue; font-size: 1em;\"> Salvataggio in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_csv_file = os.path.join(output_folder, 'peak_frequencies.csv')\n",
    "output_fits_file = os.path.join(output_folder, 'peak_frequencies.fits')\n",
    "with open(output_csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Peak Frequencies', 'Peak Power'])\n",
    "    for freq, power in zip(peak_frequencies, peak_powers):\n",
    "        writer.writerow([freq, power])\n",
    "print(f\"Data saved to {output_csv_file}\")\n",
    "hdu = fits.PrimaryHDU(data=np.array([peak_frequencies, peak_powers]))\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.writeto(output_fits_file, overwrite=True)\n",
    "print(f\"Data saved to {output_fits_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9933de",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-size: 1em;\"> Check speckle threshold da usare nel codice principale (può variare per ogni target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ome_data\n",
    "gc.collect()\n",
    "################################################################################\n",
    "file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\Algol_1kHz_1_MMStack_Pos0.ome.tif\")\n",
    "file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\febbraio\\arcturus_633nm_10ms.ome.tif\")\n",
    "#file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\\castor_40ms_elev75.tif\")\n",
    "file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\\aldebaran_40ms_elev30.tif\")\n",
    "check_radius = int(diffraction_limit_arcseconds*0.5/plate_scale) # corrisponde al raggio del disco di airy in pixel\n",
    "#print (\"Check radius in pixels: \", check_radius)\n",
    "speckle_threshold = 14000\n",
    "imagenumber = 300 \n",
    "ome_file = file\n",
    "ome_data = tifffile.imread(ome_file)[:5000]\n",
    "data_raw=ome_data[imagenumber]\n",
    "###################################################################################\n",
    "\n",
    "poisson_error = np.sqrt(data_raw)\n",
    "\n",
    "# Estimate the background error (assuming a constant background level)\n",
    "background_level = np.median(data_raw)\n",
    "background_error = np.sqrt(background_level)\n",
    "\n",
    "# Combine the signal and background errors to get the total error\n",
    "total_error = np.sqrt(poisson_error**2 + background_error**2)\n",
    "\n",
    "# Estimate the background using the total error\n",
    "background_estimate = data_raw - total_error\n",
    "\n",
    "background_estimate[background_estimate < 0] = 0\n",
    "\n",
    "print(f\"Background level: {background_level}\")\n",
    "print(f\"Background error: {background_error}\")\n",
    "print(background_estimate)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "data = data_raw - background_level\n",
    "data[data<0] = 0\n",
    "print(data.shape)\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data_raw, cmap=custom_cmap)\n",
    "plt.title('Original Image')\n",
    "plt.colorbar(label='Counts')\n",
    "\n",
    "# Plot the background subtracted image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(data, cmap=custom_cmap)\n",
    "plt.title('Background Subtracted Image')\n",
    "plt.colorbar(label='Counts')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "#data = ome_data[20]\n",
    "#speckle_threshold=1500 #10000#7000\n",
    "# Define the radius to check for a larger count\n",
    "#check_radius = 4\n",
    "\n",
    "###############################################################################################\n",
    "###########################     SOLO PER 10KHZ ################################################\n",
    "#center_y, center_x = data.shape[0] // 2, data.shape[1] // 2\n",
    "\n",
    "#search_radius = 80\n",
    "\n",
    "#y, x = np.ogrid[:data.shape[0], :data.shape[1]]\n",
    "#mask = (x - center_x)**2 + (y - center_y)**2 <= search_radius**2\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "# Apply the mask to the data to find speckles within the search radius\n",
    "speckle_coords = np.column_stack(np.where((data > speckle_threshold)))# & mask))\n",
    "\n",
    "\n",
    "# Show the image with the speckles highlighted \n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.scatter(speckle_coords[:, 1], speckle_coords[:, 0], color='chartreuse', s=2, marker='d')\n",
    "plt.title('Detected Speckles')\n",
    "plt.show()\n",
    "\n",
    "# List to store the real speckles\n",
    "real_speckles = []\n",
    "\n",
    "# Iterate over each speckle found\n",
    "for coord in speckle_coords:\n",
    "    y, x = coord\n",
    "    max_count = data[y, x]\n",
    "    speckle = coord\n",
    "    \n",
    "    # Check the surrounding pixels within the radius\n",
    "    for dy in range(-check_radius, check_radius + 1):\n",
    "        for dx in range(-check_radius, check_radius + 1):\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if 0 <= ny < data.shape[0] and 0 <= nx < data.shape[1]:\n",
    "                if data[ny, nx] > max_count:\n",
    "                    max_count = data[ny, nx]\n",
    "                    speckle = [ny, nx]\n",
    "                    \n",
    "    if not any(np.array_equal(speckle, x) for x in real_speckles):\n",
    "        real_speckles.append(speckle)\n",
    "    \n",
    "# Convert real speckles to numpy array\n",
    "real_speckles = np.array(real_speckles)\n",
    "print(real_speckles.shape)\n",
    "\n",
    "# Define the zoom factor\n",
    "zoom_factor = 2\n",
    "\n",
    "# Calculate the center of the real speckles\n",
    "center_x = int(real_speckles[:, 1].mean())\n",
    "center_y = int(real_speckles[:, 0].mean())\n",
    "\n",
    "# Define the zoomed area\n",
    "x1 = max(center_x - data.shape[1] // (2 * zoom_factor), 0)\n",
    "x2 = min(center_x + data.shape[1] // (2 * zoom_factor), data.shape[1])\n",
    "y1 = max(center_y - data.shape[0] // (2 * zoom_factor), 0)\n",
    "y2 = min(center_y + data.shape[0] // (2 * zoom_factor), data.shape[0])\n",
    "\n",
    "# Crop the zoomed area from the original image\n",
    "zoomed_image = data[y1:y2, x1:x2]\n",
    "\n",
    " \n",
    "print(\"Number of speckles found:\", len(speckle_coords))\n",
    "print(\"Number of real speckles found:\", len(real_speckles))\n",
    "\n",
    "# Save the last plot as an image with very large resolution\n",
    "fig, ax = plt.subplots(figsize=(20, 20))  # Increase the figure size for higher resolution\n",
    "ax.imshow(zoomed_image, cmap=custom_cmap)\n",
    "ax.scatter(real_speckles[:, 1] - x1, real_speckles[:, 0] - y1, color='red', s=0.5, marker='d')\n",
    "ax.set_title('Zoomed Image with Real Speckles')\n",
    "#plt.savefig('real_speckles_r=5.png', dpi=500)  # Save with high resolution\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "filtered_speckles = []\n",
    "\n",
    "for speckle in real_speckles:\n",
    "    y, x = speckle\n",
    "    max_count = data[y, x]\n",
    "    keep_speckle = True\n",
    "    # Check for speckles that are closer than N pixels\n",
    "    for other_speckle in filtered_speckles:\n",
    "        distance = np.sqrt((other_speckle[0] - y)**2 + (other_speckle[1] - x)**2)\n",
    "        if distance < 5:   # change here to change the radius (in pixels)\n",
    "            if data[other_speckle[0], other_speckle[1]] > max_count:\n",
    "                keep_speckle = False\n",
    "            else:\n",
    "                filtered_speckles = [fs for fs in filtered_speckles if not np.array_equal(fs, other_speckle)]\n",
    "    \n",
    "    if keep_speckle:\n",
    "        filtered_speckles.append([y, x])\n",
    "\n",
    "# Convert filtered speckles to numpy array\n",
    "filtered_speckles = np.array(filtered_speckles)\n",
    "\n",
    "# Print the filtered speckles\n",
    "print(\"Filtered speckles:\", len(filtered_speckles))\n",
    "\n",
    "# Define the zoom factor\n",
    "zoom_factor = 2\n",
    "\n",
    "# Calculate the center of the filtered speckles\n",
    "center_x = int(filtered_speckles[:, 1].mean())\n",
    "center_y = int(filtered_speckles[:, 0].mean())\n",
    "\n",
    "# Define the zoomed area\n",
    "x1 = max(center_x - data.shape[1] // (2 * zoom_factor), 0)\n",
    "x2 = min(center_x + data.shape[1] // (2 * zoom_factor), data.shape[1])\n",
    "y1 = max(center_y - data.shape[0] // (2 * zoom_factor), 0)\n",
    "y2 = min(center_y + data.shape[0] // (2 * zoom_factor), data.shape[0])\n",
    "\n",
    "# Crop the zoomed area from the original image\n",
    "zoomed_image = data[y1:y2, x1:x2]\n",
    "\n",
    "# Display the zoomed image with the filtered speckles highlighted\n",
    "plt.figure(figsize=(7, 7))  # Increase the figure size for larger image\n",
    "plt.imshow(zoomed_image, cmap=custom_cmap)\n",
    "plt.scatter(filtered_speckles[:, 1] - x1, filtered_speckles[:, 0] - y1, color='chartreuse', s=2, marker='d', label='Speckle center')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "###########################################################################################################\n",
    "############################################ SOLO PER 10KHZ ##############################################\n",
    "########################################################################################################\n",
    "# Calculate the barycenter of the filtered speckles\n",
    "#barycenter_x = filtered_speckles[:, 1].mean()\n",
    "#barycenter_y = filtered_speckles[:, 0].mean()\n",
    "\n",
    "# Define a maximum distance from the barycenter to consider a speckle as valid\n",
    "#max_distance = 70  \n",
    "\n",
    "# Calculate the distance of each speckle from the barycenter\n",
    "#distances = np.sqrt((filtered_speckles[:, 1] - barycenter_x)**2 + (filtered_speckles[:, 0] - barycenter_y)**2)\n",
    "\n",
    "###############################################################################################\n",
    "###########################     SOLO PER 10KHZ ################################################\n",
    "# Filter out speckles that are farther than the maximum distance from the barycenter\n",
    "# filtered_speckles = filtered_speckles[distances <= max_distance]\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "\n",
    "print(\"Filtered speckles after removing distant ones:\", len(filtered_speckles))\n",
    "plt.figure(figsize=(14, 14)) \n",
    "plt.imshow(zoomed_image, cmap=custom_cmap)\n",
    "plt.scatter(filtered_speckles[:, 1] - x1, filtered_speckles[:, 0] - y1, color='chartreuse', s=2, marker='d', label='Speckle center')\n",
    "plt.title('', fontsize='large')\n",
    "plt.legend(fontsize='large')\n",
    "plt.xticks(fontsize='large')\n",
    "plt.yticks(fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953d3273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDU Name: PRIMARY\n",
      "Header:\n",
      "  SIMPLE: True\n",
      "  BITPIX: 8\n",
      "  NAXIS: 0\n",
      "  EXTEND: True\n",
      "Data:\n",
      "None\n",
      "----------------------------------------\n",
      "HDU Name: FWHM_MEAN\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: FWHM_MEAN\n",
      "Data:\n",
      "[0.12322746 0.11668639]\n",
      "----------------------------------------\n",
      "HDU Name: FWHM_MEDIAN\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: FWHM_MEDIAN\n",
      "Data:\n",
      "[0.12466757 0.11766614]\n",
      "----------------------------------------\n",
      "HDU Name: FWHM_STD\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: FWHM_STD\n",
      "Data:\n",
      "[0.01849506 0.02176886]\n",
      "----------------------------------------\n",
      "HDU Name: CENTROID\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 2\n",
      "  NAXIS1: 2\n",
      "  NAXIS2: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: CENTROID\n",
      "Data:\n",
      "[[1116.83546098  954.40331828]\n",
      " [1112.70907926  949.09251947]]\n",
      "----------------------------------------\n",
      "HDU Name: RMS\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 2\n",
      "  NAXIS1: 2\n",
      "  NAXIS2: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: RMS\n",
      "Data:\n",
      "[[74.90536835 56.50782378]\n",
      " [79.54893333 66.0051799 ]]\n",
      "----------------------------------------\n",
      "HDU Name: MEAN_ELLIPTICITY\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 2\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: MEAN_ELLIPTICITY\n",
      "Data:\n",
      "[0.19546014 0.22943854]\n",
      "----------------------------------------\n",
      "HDU Name: PEAK_FREQUENCIES\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 0\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: PEAK_FREQUENCIES\n",
      "Data:\n",
      "[]\n",
      "----------------------------------------\n",
      "HDU Name: PEAK_POWERS\n",
      "Header:\n",
      "  XTENSION: IMAGE\n",
      "  BITPIX: -64\n",
      "  NAXIS: 1\n",
      "  NAXIS1: 0\n",
      "  PCOUNT: 0\n",
      "  GCOUNT: 1\n",
      "  EXTNAME: PEAK_POWERS\n",
      "Data:\n",
      "[]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "def extract_data_from_fits(file_path):\n",
    "    \"\"\"\n",
    "    Opens a FITS file, reads all HDUs, and extracts the data and header from each.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the FITS file.\n",
    "\n",
    "    Returns:\n",
    "    - data_dict (dict): A dictionary where keys are HDU names (or indices if no name)\n",
    "                         and values are dictionaries containing 'data' and 'header'.\n",
    "                         Returns None if the file cannot be opened or read.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hdul = fits.open(file_path)\n",
    "        data_dict = {}\n",
    "\n",
    "        for i, hdu in enumerate(hdul):\n",
    "            hdu_name = hdu.name if hdu.name else f\"HDU_{i}\"\n",
    "            data_dict[hdu_name] = {\n",
    "                'data': hdu.data,\n",
    "                'header': dict(hdu.header)  # Convert header to a standard dictionary\n",
    "            }\n",
    "        hdul.close()\n",
    "        return data_dict\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An error occurred while opening or reading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'outputs/results_aldebaran_marzo_40ms_elev30.tif.fits'  # Replace with your file path\n",
    "extracted_data = extract_data_from_fits(file_path)\n",
    "\n",
    "if extracted_data:\n",
    "    for hdu_name, content in extracted_data.items():\n",
    "        print(f\"HDU Name: {hdu_name}\")\n",
    "        print(\"Header:\")\n",
    "        for key, value in content['header'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        print(\"Data:\")\n",
    "        print(content['data'])\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No data was extracted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
