{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73acda0b",
   "metadata": {},
   "source": [
    "\n",
    "# Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import poppy\n",
    "import astropy.units as u\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from astropy.stats import sigma_clip\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from scipy.optimize import curve_fit\n",
    "import photutils\n",
    "import time\n",
    "import datetime as dt\n",
    "from scipy import fftpack\n",
    "import nbformat\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from turbustat.statistics import PowerSpectrum\n",
    "from scipy.signal import butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from astropy.io.fits import Header\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import csv\n",
    "from photutils.aperture import aperture_photometry, CircularAperture, CircularAnnulus\n",
    "from photutils.aperture import ApertureStats\n",
    "\n",
    "# Colormap\n",
    "dark_yellow = [ '#003f5c', '#2f4b7c', '#665191', '#a05195', '#d45087', '#f95d6a', '#ff7c43', '#ffa600']\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"DarkYellow\", dark_yellow)\n",
    "gradient = np.linspace(0, 1, 256).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed680f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<span style=\"color:yellow; font-size:40px;\">Variabili in input</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a17189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffraction limit in arcseconds and pixels:  0.17504418560439558 16.05909959673354\n",
      "Expected speckle size in arcseconds and pixels:  0.07035025819440659 6.45415212792721\n"
     ]
    }
   ],
   "source": [
    "############### PER SPECKLE FIT ###################################\n",
    "speckle_threshold=7000 #1100 #7000 #9500 #8000 #9000 #6500 #9000\n",
    "# Plate scale arcseconds/pixels\n",
    "plate_scale = 0.0109 # 0.012#4-MARZO #0.0109 #FEBBRAIO# 0.0377 #0.0244*2 #0.0376*2 #0.0268 marzo #0.0244 febb #0.0376 #\n",
    "# Diffraction limit of the telescope\n",
    "aperture = 1.82                                                     # Aperture of the telescope (in meters)\n",
    "wavelength = 633e-9 #700e-9                                                 # Reference wavelenght (in meters) \n",
    "diffraction_limit_radians = 2*1.22 * wavelength / aperture          # Diameter of the Airy disk\n",
    "diffraction_limit_arcseconds = diffraction_limit_radians * 206265\n",
    "expected_speckle_size_radians = 0.8038 *(1.22 * wavelength / aperture)\n",
    "expected_speckle_size = expected_speckle_size_radians * 206265  \n",
    "expected_speckle_size_pixels = expected_speckle_size / plate_scale\n",
    "# Radius use for the fit of the speckles (in pixels)\n",
    "radius=int((diffraction_limit_arcseconds/plate_scale)/2)  # raggio della zona del fit attorno alle speckle (Diametro = disco di airy)\n",
    "check_radius = int((diffraction_limit_arcseconds*0.5)/plate_scale) # raggio della zona di controllo attorno alle speckle (Diametro = disco di airy)\n",
    "print(\"Diffraction limit in arcseconds and pixels: \",diffraction_limit_arcseconds, diffraction_limit_arcseconds/plate_scale)\n",
    "print(\"Expected speckle size in arcseconds and pixels: \", expected_speckle_size, expected_speckle_size_pixels)\n",
    "\n",
    "###########    PER PSD   ##################################################\n",
    "ordine = 5 #  NON OLTRE 6\n",
    "imagenumber = 300 #500\n",
    "stacked = False  # Fa PSD di più immagini sommate (3 al momento)\n",
    "nstack = 3 # immagini da sommare se si vuole usare il Power specrum di immagini sommate\n",
    "lowcut_pix = 14#15#7  #max dimension in pixel\n",
    "highcut_pix = 4#9#2.1  #min dimension in pixel\n",
    "lowcut= 1/lowcut_pix \n",
    "highcut = 1/highcut_pix\n",
    "crop_size = 2000   # FORMATO IMMAGINE FINALE: N pixel X N pixel (dimiuisce la dimensione dell'immagine per velocizzare i calcoli)\n",
    "frequency_range = 0.15    # range per trovare il picco delle spckle (centrato nella frequenza delle speckle teorica)\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6dc17",
   "metadata": {},
   "source": [
    "## <span style=\"color:green; font-size: 1em;\"> Lettura file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\Algol_1kHz_1_MMStack_Pos0.ome.tif\")\n",
    "file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\febbraio\\arcturus_633nm_10ms.ome.tif\")\n",
    "#file = (r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\\Castor.tif\")\n",
    "#file =(r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\\aldebaran_40ms_elev30.tif\")\n",
    "immagini = tifffile.imread(file)[:5000] # LIMITE DI 5000 IMMAGINI PER EVITARE PROBLEMI DI MEMORIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7e3e3",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange; font-size: 1em;\"> Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b20887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcProcessTime(starttime, cur_iter, max_iter):\n",
    "\n",
    "    telapsed = time.time() - starttime\n",
    "    testimated = (telapsed/cur_iter)*(max_iter)\n",
    "    finishtime = starttime + testimated\n",
    "    finishtime = dt.datetime.fromtimestamp(finishtime).strftime(\"%H:%M:%S\")\n",
    "    lefttime = testimated-telapsed \n",
    "\n",
    "    return (int(telapsed), int(lefttime), finishtime)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale):\n",
    "    fwhm_results = []\n",
    "    centers = []\n",
    "    \n",
    "    for speckle in filtered_speckles:\n",
    "        y_ref, x_ref = speckle  \n",
    "        masked_data = data.copy() \n",
    "        y, x = np.mgrid[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data = masked_data[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data[masked_data < 0] = 0 \n",
    "        \n",
    "        ###########################################################################\n",
    "        #Se attivo, fa il fit in una regione circolare\n",
    "        distance = np.sqrt((x - x_ref)**2 + (y - y_ref)**2)\n",
    "        circular_mask = distance <= radius\n",
    "        masked_data = np.where(circular_mask, masked_data, 0)\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Set border pixels to 0\n",
    "        masked_data[0, :] = 0\n",
    "        masked_data[-1, :] = 0\n",
    "        masked_data[:, 0] = 0\n",
    "        masked_data[:, -1] = 0\n",
    "\n",
    "        gaussian_model = models.Gaussian2D(amplitude=masked_data.max(), x_mean=x_ref, y_mean=y_ref, x_stddev=0.5, y_stddev=0.5)\n",
    "        gaussian_model.amplitude.min = speckle_threshold\n",
    "        gaussian_model.amplitude.max = masked_data.max()\n",
    "        gaussian_model.x_mean.min = x_ref - 5   # METTERE A 1 PER LE SPECKLE A 3X\n",
    "        gaussian_model.x_mean.max = x_ref + 5\n",
    "        gaussian_model.y_mean.min = y_ref - 5\n",
    "        gaussian_model.y_mean.max = y_ref + 5\n",
    "\n",
    "        fitter = fitting.LevMarLSQFitter()\n",
    "        fitted_model = fitter(gaussian_model, x, y, masked_data)\n",
    "\n",
    "        fwhm_x = 2.355 * fitted_model.x_stddev.value * plate_scale\n",
    "        fwhm_y = 2.355 * fitted_model.y_stddev.value * plate_scale\n",
    "        fwhm_results.append((fwhm_y, fwhm_x))\n",
    "        centers.append((fitted_model.y_mean.value, fitted_model.x_mean.value))\n",
    "\n",
    "    return np.array(fwhm_results), np.array(centers)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def gaussiana(bins, media, sigma):\n",
    "\tx = np.zeros(len(bins)-1)\n",
    "\tfor i in range(len(x)):\n",
    "\t\tx[i] = (bins[i]+bins[i+1])/2\n",
    "\ty = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-(x-media)**2/(2*sigma**2))\n",
    "\treturn x, y\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def calculate_2dft(input):\n",
    "    ft = np.fft.ifftshift(input)\n",
    "    ft = np.fft.fft2(ft)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def butterworth_2d_bandpass(image, lowcut, highcut, order=5):\n",
    "    ny, nx = image.shape\n",
    "    y, x = np.ogrid[:ny, :nx]\n",
    "    cy, cx = ny // 2, nx // 2\n",
    "    # Create normalized radius grid (distance from center)\n",
    "    radius = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    radius /= np.max(radius)  # Normalize to [0, 1]\n",
    "    # Normalize lowcut/highcut to [0, 1] as fraction of Nyquist\n",
    "    low = lowcut * 2\n",
    "    high = highcut * 2\n",
    "    # Butterworth bandpass formula\n",
    "    def butterworth(freq, cutoff, n):\n",
    "        return 1 / (1 + (freq / cutoff)**(2 * n))\n",
    "    # Bandpass = Highpass * Lowpass\n",
    "    lowpass = butterworth(radius, high, order)\n",
    "    highpass = 1 - butterworth(radius, low, order)\n",
    "    bandpass_mask = lowpass * highpass\n",
    "    # Apply filter in frequency domain\n",
    "    fft_image = np.fft.fft2(image)\n",
    "    fft_shifted = np.fft.fftshift(fft_image)\n",
    "    filtered_fft = fft_shifted * bandpass_mask\n",
    "    filtered_image = np.fft.ifft2(np.fft.ifftshift(filtered_fft)).real\n",
    "    return filtered_image, bandpass_mask\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def crop_center(image, size):\n",
    "    \"\"\"\n",
    "    Crop a square region of given size around the image center.\n",
    "\n",
    "    \"\"\"\n",
    "    ny, nx = image.shape\n",
    "    cx, cy = nx // 2, ny // 2\n",
    "    half = size // 2\n",
    "    x_min = cx - half\n",
    "    x_max = cx + half\n",
    "    y_min = cy - half\n",
    "    y_max = cy + half\n",
    "    return image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def plot_psd_peak(freqs, ps1D, largest_peak_freq, frequency_range, expected_speckle_size, plate_scale):\n",
    "    zoom_range = (largest_peak_freq - frequency_range / 2, largest_peak_freq + frequency_range / 2)\n",
    "    zoom_indices = (freqs >= zoom_range[0]) & (freqs <= zoom_range[1])\n",
    "    zoom_freqs = freqs[zoom_indices]\n",
    "    zoom_power = ps1D[zoom_indices]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.loglog(zoom_freqs, zoom_power, label='Zoomed Power Spectrum')  # Emphasize the zoomed region\n",
    "    plt.axvline(x=largest_peak_freq, color='red', linestyle='--', label=f'Peak: {largest_peak_freq:.4f} pix⁻¹')\n",
    "    plt.axvline(x=1/(expected_speckle_size/plate_scale), color='magenta', linestyle='--', label='Expected Speckle Size')\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.xlabel(\"Spatial Frequency [pix⁻¹]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.grid(True, which=\"both\", linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "##################################################################################\n",
    "######################################################################################\n",
    "def find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range):\n",
    "    \"\"\"\n",
    "    frequency_range : Range around the expected speckle frequency to search for the peak.\n",
    "    largest_peak_freq : Frequency with the largest power within the specified range.\n",
    "    largest_peak_power : Largest power within the specified frequency range.\n",
    "    \"\"\"\n",
    "    expected_speckle_frequency = 1 / expected_speckle_size_pixels\n",
    "    lower_freq = expected_speckle_frequency - frequency_range / 2\n",
    "    upper_freq = expected_speckle_frequency + frequency_range / 2\n",
    "    #print(expected_speckle_size_pixels,expected_speckle_frequency, lower_freq, upper_freq)\n",
    "    peak_indices = (freqs >= lower_freq) & (freqs <= upper_freq)\n",
    "\n",
    "    if not any(peak_indices):\n",
    "        print(\"No frequencies selected within the specified range.\")\n",
    "        return None, None\n",
    "\n",
    "    selected_freqs = freqs[peak_indices]\n",
    "    selected_power = ps1D[peak_indices]\n",
    "    largest_peak_index = np.argmax(selected_power)\n",
    "    largest_peak_freq = selected_freqs[largest_peak_index]\n",
    "    largest_peak_power = selected_power[largest_peak_index]\n",
    "    \n",
    "    return largest_peak_freq, largest_peak_power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ffaf9",
   "metadata": {},
   "source": [
    "# <span style=\"color:red; font-size: 1em;\"> Codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tifffile:<tifffile.TiffFile 'arcturus_633nm_10ms.ome.tif'> MMStack file name is invalid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tifffile:<tifffile.TiffFile 'arcturus_633nm_10ms.ome.tif'> MMStack series is missing files. Returning subset (1, 8136, 1, 1) of (1, 10000, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files in the folder\n",
      "Loaded data from arcturus_633nm_10ms.ome.tif\n",
      "Analysing arcturus_633nm_10ms.ome.tif\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "folder_path = r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\febbraio\"\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "#immagini_list = []\n",
    "for file in file_list: \n",
    "    print(f\"Found {len(file_list)} files in the folder\")\n",
    "    file_name = os.path.basename(file)\n",
    "    immagini = tifffile.imread(file)[:5000]\n",
    "    #immagini_list.append(immagini)\n",
    "    print(f\"Loaded data from {file_name}\")\n",
    "    print(f'Analysing {file_name}...')\n",
    "    \n",
    "    ############# SPECKLE FIT ##########################################################\n",
    "    \n",
    "    start = time.time()\n",
    "    fwhm_single_image = []\n",
    "    fwhm_mean_all = []\n",
    "    fwhm_median_all = []\n",
    "    fwhm_std_all = []\n",
    "    centroid_all = []   # first coordinate in the array is the Y\n",
    "    rms_all = []        # first coordinate in the array is the Y\n",
    "    fwhm_mean_filtered_all = []\n",
    "    fwhm_median_filtered_all = []\n",
    "    fwhm_std_filtered_all = []\n",
    "    rms_filtered_all = []\n",
    "    centroid_filtered_all = []\n",
    "    ellipticity_mean_all=[]\n",
    "\n",
    "    for imagenumber in range(len(immagini)):\n",
    "        data_raw = immagini[imagenumber]\n",
    "        data_clean = data_raw\n",
    "        poisson_error = np.sqrt(data_raw)\n",
    "        background_level = np.median(data_raw)\n",
    "        background_error = np.sqrt(background_level)\n",
    "        noise = np.sqrt(np.mean(poisson_error**2) + background_error**2)\n",
    "        background_estimate = data_raw - noise\n",
    "        background_estimate[background_estimate < 0] = 0\n",
    "        data = data_raw - background_level\n",
    "        data[data < 0] = 0\n",
    "\n",
    "        ###########################     SOLO PER 10KHZ ################################################\n",
    "        #center_y, center_x = data.shape[0] // 2, data.shape[1] // 2\n",
    "        #search_radius = 80  ###per speckle a 3x\n",
    "        #y, x = np.ogrid[:data.shape[0], :data.shape[1]]\n",
    "        #mask = (x - center_x)**2 + (y - center_y)**2 <= search_radius**2\n",
    "        #speckle_coords = np.column_stack(np.where((data > speckle_threshold) & mask))\n",
    "        ################################################################################################\n",
    "        # QUANDO NON ATTIVO SPECKLE A 10KHZ\n",
    "        speckle_coords = np.column_stack(np.where(data > speckle_threshold))\n",
    "        real_speckles = []\n",
    "\n",
    "        for coord in speckle_coords:\n",
    "            y, x = coord\n",
    "            max_count = data[y, x]\n",
    "            speckle = coord\n",
    "            # Check the surrounding pixels within the radius\n",
    "            for dy in range(-check_radius, check_radius + 1):\n",
    "                for dx in range(-check_radius, check_radius + 1):\n",
    "                    ny, nx = y + dy, x + dx\n",
    "                    if 0 <= ny < data.shape[0] and 0 <= nx < data.shape[1]:\n",
    "                        if data[ny, nx] > max_count:\n",
    "                            max_count = data[ny, nx]\n",
    "                            speckle = [ny, nx]           \n",
    "            if not any(np.array_equal(speckle, x) for x in real_speckles):\n",
    "                real_speckles.append(speckle)\n",
    "                \n",
    "        real_speckles = np.array(real_speckles)\n",
    "        filtered_speckles = []\n",
    "                \n",
    "        for speckle in real_speckles:\n",
    "            y, x = speckle\n",
    "            max_count = data[y, x]\n",
    "            keep_speckle = True\n",
    "            # Check for speckles that are closer than N pixels\n",
    "            for other_speckle in filtered_speckles:\n",
    "                distance = np.sqrt((other_speckle[0] - y)**2 + (other_speckle[1] - x)**2)\n",
    "                if distance < 5:   # change here to change the radius (in pixels)\n",
    "                    if data[other_speckle[0], other_speckle[1]] > max_count:\n",
    "                        keep_speckle = False\n",
    "                    else:\n",
    "                        filtered_speckles = [fs for fs in filtered_speckles if not np.array_equal(fs, other_speckle)]\n",
    "            if keep_speckle:\n",
    "                filtered_speckles.append([y, x])\n",
    "\n",
    "        filtered_speckles = np.array(filtered_speckles)\n",
    "    ###################################à SOLO PER 10KHZ ##############################################  \n",
    "        # Calculate the barycenter of the filtered speckles\n",
    "        #barycenter_x = filtered_speckles[:, 1].mean()\n",
    "        #barycenter_y = filtered_speckles[:, 0].mean()\n",
    "    # Define a maximum distance from the barycenter to consider a speckle as valid\n",
    "        #max_distance = 50  \n",
    "        #distances = np.sqrt((filtered_speckles[:, 1] - barycenter_x)**2 + (filtered_speckles[:, 0] - barycenter_y)**2)\n",
    "        #filtered_speckles = filtered_speckles[distances <= max_distance] \n",
    "    #############################################################################\n",
    "\n",
    "       \n",
    "        fwhm_single_image, centers = fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale)\n",
    "\n",
    "\n",
    "        ellipticity_single_image = 1 - np.minimum(fwhm_single_image[:, 0], fwhm_single_image[:, 1]) / np.maximum(fwhm_single_image[:, 0], fwhm_single_image[:, 1])\n",
    "\n",
    "        #tutto con indice 1 perché si sta facendo statistica solo sulla X\n",
    "        fwhm_x_clipped = sigma_clip(fwhm_single_image[:, 1], sigma=3, maxiters=1)  # o 1 a 3 sigma o 3 a 3.5 sigma\n",
    "        fwhm_x_tot_clean = fwhm_single_image[~fwhm_x_clipped.mask]\n",
    "        mean_clipped_fwhm = np.mean(fwhm_x_tot_clean[:,1])\n",
    "        median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean[:,1])\n",
    "        std_clipped_fwhm = np.std(fwhm_x_tot_clean[:,1]) \n",
    "        centroid = (np.mean(centers[:,0]), np.mean(centers[:,1])) \n",
    "        rms = (np.sqrt(np.mean((centers[:,0] - centroid[0])**2)), np.sqrt(np.mean((centers[:,1] - centroid[1])**2))) \n",
    "        # mean_clipped_fwhm = np.mean(fwhm_x_tot_clean)\n",
    "        # median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean)\n",
    "        # std_clipped_fwhm = np.std(fwhm_x_tot_clean)\n",
    "\n",
    "        # Store results for all speckles\n",
    "        fwhm_mean_all.append(mean_clipped_fwhm)\n",
    "        fwhm_median_all.append(median_clipped_fwhm)\n",
    "        fwhm_std_all.append(std_clipped_fwhm)\n",
    "        rms_all.append(rms)\n",
    "        centroid_all.append(centroid)\n",
    "        ellipticity_mean_all.append(np.mean(ellipticity_single_image))\n",
    "        \n",
    "        if imagenumber % 500 == 0:\n",
    "            prstime = calcProcessTime(start, imagenumber +1 ,len(immagini))\n",
    "            print(\"time elapsed: %s s, time left: %s s, estimated finish time: %s\"%prstime)\n",
    "            \n",
    "    print('Speckles fit done')\n",
    "        \n",
    "############# SALVATAGGIO RISULTATI ############################\n",
    "    primary_hdu = fits.PrimaryHDU()\n",
    "    fwhm_mean_hdu = fits.ImageHDU(data=np.array(fwhm_mean_all), name='FWHM_MEAN')\n",
    "    fwhm_median_hdu = fits.ImageHDU(data=np.array(fwhm_median_all), name='FWHM_MEDIAN')\n",
    "    fwhm_std_hdu = fits.ImageHDU(data=np.array(fwhm_std_all), name='FWHM_STD')\n",
    "    centroid_hdu = fits.ImageHDU(data=np.array(centroid_all), name='CENTROID')\n",
    "    rms_hdu = fits.ImageHDU(data=np.array(rms_all), name='RMS')\n",
    "    ellipticity_means_hdu = fits.ImageHDU(data=np.array(ellipticity_mean_all), name = 'MEAN ELLIPTICITY')\n",
    "    hdul = fits.HDUList([primary_hdu, fwhm_mean_hdu, fwhm_median_hdu, fwhm_std_hdu, centroid_hdu, rms_hdu])\n",
    "    hdul.writeto(f'outputs\\results{file_name}.fits', overwrite=True)\n",
    "    hdul.close()\n",
    "    print('Speckle fit data saved')\n",
    "\n",
    "######################## SPECKLE PSD ######################\n",
    "\n",
    "    print(f'Power Spectrum of{file_name}...')\n",
    "    \n",
    "    header = Header()\n",
    "    header['CDELT1'] = 1.0\n",
    "    header['CDELT2'] = 1.0\n",
    "    peak_frequencies = []\n",
    "    peak_powers = []\n",
    "\n",
    "    for i, image in enumerate(immagini):\n",
    "        \n",
    "        largest_peak_freq = None\n",
    "        largest_peak_power = None\n",
    "        \n",
    "        if stacked and i + nstack <= len(immagini):\n",
    "            data = np.sum(immagini[i:i + 3], axis=0)\n",
    "        else:\n",
    "            data = image\n",
    "        image_cropped = crop_center(data, crop_size)\n",
    "        data = image_cropped.copy()\n",
    "        background_level = np.median(data)\n",
    "        data = data - background_level\n",
    "        data[data < 0] = 0\n",
    "        image = data.copy()\n",
    "\n",
    "        # Apply 2D Butterworth bandpass\n",
    "        filtered_image, mask = butterworth_2d_bandpass(image, lowcut, highcut, ordine)\n",
    "        # Normalize filtered image\n",
    "        filtered_image = np.nan_to_num(filtered_image, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        filtered_image[filtered_image < 0] = 0\n",
    "        filtered_image /= (np.max(filtered_image) + 1e-8)\n",
    "\n",
    "        # Compute power spectrum\n",
    "        pspec_filtered = PowerSpectrum(filtered_image, header=header, distance=1 * u.pc)\n",
    "        pspec_filtered.run(verbose=False, xunit=u.pix**-1)\n",
    "        \n",
    "        freqs = pspec_filtered.freqs.value\n",
    "        ps1D = pspec_filtered.ps1D\n",
    "        largest_peak_freq, largest_peak_power = find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range)\n",
    "\n",
    "        if largest_peak_freq is not None and largest_peak_power is not None:\n",
    "            print(f\"Largest peak frequency: {largest_peak_freq:.4f} pix⁻¹\")\n",
    "            print(f\"Largest peak power: {largest_peak_power:.2f}\")\n",
    "            #print(f\"Expected speckle size: {expected_speckle_size:.4f} arcsec\")\n",
    "            #print(f\"Expected speckle size in pixels: {expected_speckle_size_pixels:.4f} pixels\")\n",
    "            #plot_psd_peak(freqs, ps1D, largest_peak_freq, frequency_range, expected_speckle_size, plate_scale)\n",
    "        else:\n",
    "            print(\"Could not find any peaks within the specified frequency range.\")\n",
    "\n",
    "        peak_frequencies.append(largest_peak_freq)\n",
    "        peak_powers.append(largest_peak_power)\n",
    "        print(f'Power Spectrum of {file_name} done')\n",
    "        \n",
    "        ## salvataggio risultati\n",
    "        output_folder = 'outputs\\PSD{file_name}'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_csv_file = os.path.join(output_folder, 'peak_frequencies.csv')\n",
    "        output_fits_file = os.path.join(output_folder, 'peak_frequencies.fits')\n",
    "        with open(output_csv_file, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Peak Frequencies', 'Peak Power'])\n",
    "            for freq, power in zip(peak_frequencies, peak_powers):\n",
    "                writer.writerow([freq, power])\n",
    "        print(f\"Data saved to {output_csv_file}\")\n",
    "        hdu = fits.PrimaryHDU(data=np.array([peak_frequencies, peak_powers]))\n",
    "        hdul = fits.HDUList([hdu])\n",
    "        hdul.writeto(output_fits_file, overwrite=True)\n",
    "        print(f\"Data saved to {output_fits_file}\")\n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    del immagini\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138b2af",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue; font-size: 1em;\"> Salvataggio in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_csv_file = os.path.join(output_folder, 'peak_frequencies.csv')\n",
    "output_fits_file = os.path.join(output_folder, 'peak_frequencies.fits')\n",
    "with open(output_csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Peak Frequencies', 'Peak Power'])\n",
    "    for freq, power in zip(peak_frequencies, peak_powers):\n",
    "        writer.writerow([freq, power])\n",
    "print(f\"Data saved to {output_csv_file}\")\n",
    "hdu = fits.PrimaryHDU(data=np.array([peak_frequencies, peak_powers]))\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.writeto(output_fits_file, overwrite=True)\n",
    "print(f\"Data saved to {output_fits_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
