{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import poppy\n",
    "import astropy.units as u\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from astropy.stats import sigma_clip\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "from scipy.optimize import curve_fit\n",
    "import photutils\n",
    "import time\n",
    "import datetime as dt\n",
    "from scipy import fftpack\n",
    "import nbformat\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from turbustat.statistics import PowerSpectrum\n",
    "from scipy.signal import butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from astropy.io.fits import Header\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import csv\n",
    "import gc\n",
    "import re\n",
    "from photutils.aperture import aperture_photometry, CircularAperture, CircularAnnulus\n",
    "from photutils.aperture import ApertureStats\n",
    "from astropy.table import Table\n",
    "import warnings\n",
    "from astropy.utils.exceptions import AstropyUserWarning\n",
    "import winsound\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "\n",
    "\n",
    "############### PER SPECKLE FIT ###################################\n",
    "speckle_thresholds=[3000, 4000, 10000]  # l'ultimo era 12000 primada cambiare a seconda dei target usati prima era 3000 non 2000\n",
    "speckle_threshold=7000 #1100 #7000 #9500 #8000 #9000 #6500 #9000\n",
    "# Plate scale arcseconds/pixels\n",
    "plate_scales=[0.0377,  0.0109, 0.012]  #plate cslae di gennaio, febbraio e marzo rispettivamente\n",
    "plate_scale = 0.0109 # 0.012#4-MARZO #0.0109 #FEBBRAIO# 0.0377 #0.0244*2 #0.0376*2 #0.0268 marzo #0.0244 febb #0.0376 #\n",
    "# Diffraction limit of the telescope\n",
    "aperture = 1.82                                                     # Aperture of the telescope (in meters)\n",
    "wavelength = 633e-9 #700e-9                                                 # Reference wavelenght (in meters) \n",
    "diffraction_limit_radians = 2*1.22 * wavelength / aperture          # Diameter of the Airy disk\n",
    "diffraction_limit_arcseconds = diffraction_limit_radians * 206265\n",
    "expected_speckle_size_radians = 0.8038 *(1.22 * wavelength / aperture)\n",
    "expected_speckle_size = expected_speckle_size_radians * 206265  \n",
    "expected_speckle_size_pixels = expected_speckle_size / plate_scale\n",
    "# Radius use for the fit of the speckles (in pixels)\n",
    "radius=int((diffraction_limit_arcseconds/plate_scale)/2)  # raggio della zona del fit attorno alle speckle (Diametro = disco di airy)\n",
    "check_radius = int((diffraction_limit_arcseconds*0.5)/plate_scale) # raggio della zona di controllo attorno alle speckle (Diametro = disco di airy)\n",
    "mindist = 5 #distanza dimina in pixel tra 2 speckle (per evitare che la stessa speckle venga contata più volte)\n",
    "#print(\"Diffraction limit in arcseconds and pixels: \",diffraction_limit_arcseconds, diffraction_limit_arcseconds/plate_scale)\n",
    "print(\"Expected speckle size in arcseconds and pixels: \", expected_speckle_size, expected_speckle_size_pixels)\n",
    "\n",
    "###########    PER PSD   ##################################################\n",
    "ordine = 5 #  NON OLTRE 6\n",
    "imagenumber = 300 #500\n",
    "stacked = False  # Fa PSD di più immagini sommate (3 al momento)\n",
    "nstack = 3 # immagini da sommare se si vuole usare il Power specrum di immagini sommate\n",
    "lowcut_pix = 14#15#7  #max dimension in pixel\n",
    "highcut_pix = 4#9#2.1  #min dimension in pixel\n",
    "lowcut= 1/lowcut_pix \n",
    "highcut = 1/highcut_pix\n",
    "crop_size = 2000   # FORMATO IMMAGINE FINALE: N pixel X N pixel (dimiuisce la dimensione dell'immagine per velocizzare i calcoli)\n",
    "frequency_range = 0.15    # range per trovare il picco delle spckle (centrato nella frequenza delle speckle teorica)\n",
    "########################################################\n",
    "\n",
    "def calcProcessTime(starttime, cur_iter, max_iter):\n",
    "\n",
    "    telapsed = time.time() - starttime\n",
    "    testimated = (telapsed/cur_iter)*(max_iter)\n",
    "    finishtime = starttime + testimated\n",
    "    finishtime = dt.datetime.fromtimestamp(finishtime).strftime(\"%H:%M:%S\")\n",
    "    lefttime = testimated-telapsed \n",
    "\n",
    "    return (int(telapsed), int(lefttime), finishtime)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale):\n",
    "    fwhm_results = []\n",
    "    centers = []\n",
    "    \n",
    "    for speckle in filtered_speckles:\n",
    "        y_ref, x_ref = speckle  \n",
    "        masked_data = data.copy() \n",
    "        y, x = np.mgrid[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data = masked_data[y_ref-radius:y_ref+radius+1, x_ref-radius:x_ref+radius+1]\n",
    "        masked_data[masked_data < 0] = 0 \n",
    "        \n",
    "        ###########################################################################\n",
    "        #Se attivo, fa il fit in una regione circolare\n",
    "        distance = np.sqrt((x - x_ref)**2 + (y - y_ref)**2)\n",
    "        circular_mask = distance <= radius\n",
    "        masked_data = np.where(circular_mask, masked_data, 0)\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Set border pixels to 0\n",
    "        masked_data[0, :] = 0\n",
    "        masked_data[-1, :] = 0\n",
    "        masked_data[:, 0] = 0\n",
    "        masked_data[:, -1] = 0\n",
    "\n",
    "        gaussian_model = models.Gaussian2D(amplitude=masked_data.max(), x_mean=x_ref, y_mean=y_ref, x_stddev=0.5, y_stddev=0.5)\n",
    "        gaussian_model.amplitude.min = speckle_threshold\n",
    "        gaussian_model.amplitude.max = masked_data.max()\n",
    "        gaussian_model.x_mean.min = x_ref - 5   # METTERE A 1 PER LE SPECKLE A 3X\n",
    "        gaussian_model.x_mean.max = x_ref + 5\n",
    "        gaussian_model.y_mean.min = y_ref - 5\n",
    "        gaussian_model.y_mean.max = y_ref + 5\n",
    "\n",
    "        fitter = fitting.LevMarLSQFitter()\n",
    "        fitted_model = fitter(gaussian_model, x, y, masked_data)\n",
    "\n",
    "        fwhm_x = 2.355 * fitted_model.x_stddev.value * plate_scale\n",
    "        fwhm_y = 2.355 * fitted_model.y_stddev.value * plate_scale\n",
    "        fwhm_results.append((fwhm_y, fwhm_x))\n",
    "        centers.append((fitted_model.y_mean.value, fitted_model.x_mean.value))\n",
    "\n",
    "    return np.array(fwhm_results), np.array(centers)\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def gaussiana(bins, media, sigma):\n",
    "\tx = np.zeros(len(bins)-1)\n",
    "\tfor i in range(len(x)):\n",
    "\t\tx[i] = (bins[i]+bins[i+1])/2\n",
    "\ty = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-(x-media)**2/(2*sigma**2))\n",
    "\treturn x, y\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def calculate_2dft(input):\n",
    "    ft = np.fft.ifftshift(input)\n",
    "    ft = np.fft.fft2(ft)\n",
    "    return np.fft.fftshift(ft)\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def butterworth_2d_bandpass(image, lowcut, highcut, order=5):\n",
    "    ny, nx = image.shape\n",
    "    y, x = np.ogrid[:ny, :nx]\n",
    "    cy, cx = ny // 2, nx // 2\n",
    "    # Create normalized radius grid (distance from center)\n",
    "    radius = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    radius /= np.max(radius)  # Normalize to [0, 1]\n",
    "    # Normalize lowcut/highcut to [0, 1] as fraction of Nyquist\n",
    "    low = lowcut * 2\n",
    "    high = highcut * 2\n",
    "    # Butterworth bandpass formula\n",
    "    def butterworth(freq, cutoff, n):\n",
    "        return 1 / (1 + (freq / cutoff)**(2 * n))\n",
    "    # Bandpass = Highpass * Lowpass\n",
    "    lowpass = butterworth(radius, high, order)\n",
    "    highpass = 1 - butterworth(radius, low, order)\n",
    "    bandpass_mask = lowpass * highpass\n",
    "    # Apply filter in frequency domain\n",
    "    fft_image = np.fft.fft2(image)\n",
    "    fft_shifted = np.fft.fftshift(fft_image)\n",
    "    filtered_fft = fft_shifted * bandpass_mask\n",
    "    filtered_image = np.fft.ifft2(np.fft.ifftshift(filtered_fft)).real\n",
    "    return filtered_image, bandpass_mask\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def crop_center(image, size):\n",
    "    \"\"\"\n",
    "    Crop a square region of given size around the image center.\n",
    "\n",
    "    \"\"\"\n",
    "    ny, nx = image.shape\n",
    "    cx, cy = nx // 2, ny // 2\n",
    "    half = size // 2\n",
    "    x_min = cx - half\n",
    "    x_max = cx + half\n",
    "    y_min = cy - half\n",
    "    y_max = cy + half\n",
    "    return image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "\n",
    "def plot_psd_peak(freqs, ps1D, largest_peak_freq, frequency_range, expected_speckle_size, plate_scale):\n",
    "    zoom_range = (largest_peak_freq - frequency_range / 2, largest_peak_freq + frequency_range / 2)\n",
    "    zoom_indices = (freqs >= zoom_range[0]) & (freqs <= zoom_range[1])\n",
    "    zoom_freqs = freqs[zoom_indices]\n",
    "    zoom_power = ps1D[zoom_indices]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.loglog(zoom_freqs, zoom_power, label='Zoomed Power Spectrum')  # Emphasize the zoomed region\n",
    "    plt.axvline(x=largest_peak_freq, color='red', linestyle='--', label=f'Peak: {largest_peak_freq:.4f} pix⁻¹')\n",
    "    plt.axvline(x=1/(expected_speckle_size/plate_scale), color='magenta', linestyle='--', label='Expected Speckle Size')\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.xlabel(\"Spatial Frequency [pix⁻¹]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.title(\"Zoomed View of Power Spectrum near Largest Peak\")\n",
    "    plt.grid(True, which=\"both\", linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "##################################################################################\n",
    "######################################################################################\n",
    "def find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range):\n",
    "    \"\"\"\n",
    "    frequency_range : Range around the expected speckle frequency to search for the peak.\n",
    "    largest_peak_freq : Frequency with the largest power within the specified range.\n",
    "    largest_peak_power : Largest power within the specified frequency range.\n",
    "    \"\"\"\n",
    "    expected_speckle_frequency = 1 / expected_speckle_size_pixels\n",
    "    lower_freq = expected_speckle_frequency - frequency_range / 2\n",
    "    upper_freq = expected_speckle_frequency + frequency_range / 2\n",
    "    #print(expected_speckle_size_pixels,expected_speckle_frequency, lower_freq, upper_freq)\n",
    "    peak_indices = (freqs >= lower_freq) & (freqs <= upper_freq)\n",
    "\n",
    "    if not any(peak_indices):\n",
    "        print(\"No frequencies selected within the specified range.\")\n",
    "        return None, None\n",
    "\n",
    "    selected_freqs = freqs[peak_indices]\n",
    "    selected_power = ps1D[peak_indices]\n",
    "    largest_peak_index = np.argmax(selected_power)\n",
    "    largest_peak_freq = selected_freqs[largest_peak_index]\n",
    "    largest_peak_power = selected_power[largest_peak_index]\n",
    "    \n",
    "    return largest_peak_freq, largest_peak_power\n",
    "#################################################################################\n",
    "##################################################################################\n",
    "def scale_and_speckle_selector(plate_scales, speckle_thresholds, file):\n",
    "    if 'arcturus' in file:\n",
    "        speckle_threshold = speckle_thresholds[1]\n",
    "    if 'castor' in file:\n",
    "        speckle_threshold = speckle_thresholds[0]\n",
    "    if 'aldebaran' in file:\n",
    "        speckle_threshold = speckle_thresholds[2]   \n",
    "    if 'febbraio' in file:\n",
    "        plate_scale = plate_scales[1]\n",
    "    if 'marzo' in file:\n",
    "        plate_scale = plate_scales[2]\n",
    "    print(\"Plate scale in arcseconds/pixel: \", plate_scale)\n",
    "    print(\"Speckle threshold: \", speckle_threshold)\n",
    "    return plate_scale, speckle_threshold\n",
    "#######################################################################################################################\n",
    "#######################################################################################################################\n",
    "def code_end_alert():\n",
    "    duration = 5000  # milliseconds\n",
    "    freqs = [440, 550, 660, 770, 880, 990]  # A few different frequencies\n",
    "    for freq in freqs:\n",
    "        winsound.Beep(freq, duration // len(freqs))  # Divide duration to keep total time similar\n",
    "    freqs = freqs[:-1]\n",
    "    for freq in reversed(freqs):\n",
    "        winsound.Beep(freq, duration // (len(freqs)+1))\n",
    "    print(\"Code execution completed\")\n",
    "########################################################################################################\n",
    "#######################################################################################################\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='astropy')\n",
    "\n",
    "\n",
    "folder_path = r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\"\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "#immagini_list = []\n",
    "\n",
    "all_dfs = []  # lista per accumulare i DataFrame di ogni file\n",
    "raw_spectra_all_tot = []\n",
    "\n",
    "print(f\"Found {len(file_list)} files in the folder\")\n",
    "for file in file_list: \n",
    "    #file = r\"C:\\Users\\buonc\\OneDrive - Alma Mater Studiorum Università di Bologna\\Documents\\Astrophysics and Cosmology\\TESI\\dati\\marzo\\4-03\\castor_marzo_40ms_elev75.tif\"\n",
    "    file_name = os.path.basename(file)\n",
    "    immagini = tifffile.imread(file)[:2000]  #immagini_list.append(immagini)\n",
    "    print(f\"Loaded data from {file_name}\")\n",
    "    print(f'Analysing {file_name}...')\n",
    "    \n",
    "    plate_scale, speckle_threshold = scale_and_speckle_selector(plate_scales, speckle_thresholds, file_name)\n",
    "    diffraction_limit_radians = 2*1.22 * wavelength / aperture          # Diameter of the Airy disk\n",
    "    diffraction_limit_arcseconds = diffraction_limit_radians * 206265\n",
    "    expected_speckle_size_radians = 0.8038 *(1.22 * wavelength / aperture)\n",
    "    expected_speckle_size = expected_speckle_size_radians * 206265  \n",
    "    expected_speckle_size_pixels = expected_speckle_size / plate_scale\n",
    "    # Radius use for the fit of the speckles (in pixels)\n",
    "    radius=int((diffraction_limit_arcseconds/plate_scale)/2)  # raggio della zona del fit attorno alle speckle (Diametro = disco di airy)\n",
    "    check_radius = int((diffraction_limit_arcseconds*0.5)/plate_scale) # raggio della zona di controllo attorno alle speckle (Diametro = disco di airy)\n",
    "    #mindist = 5 #distanza dimina in pixel tra 2 speckle (per evitare che la stessa speckle venga contata più volte)\n",
    "    \n",
    "    # ############# SPECKLE FIT ##########################################################\n",
    "    \n",
    "    # start = time.time()\n",
    "    # fwhm_single_image = []\n",
    "    # fwhm_mean_all = []\n",
    "    # fwhm_median_all = []\n",
    "    # fwhm_std_all = []\n",
    "    # centroid_all = []   # first coordinate in the array is the Y\n",
    "    # rms_all = []        # first coordinate in the array is the Y\n",
    "    # fwhm_mean_filtered_all = []\n",
    "    # fwhm_median_filtered_all = []\n",
    "    # fwhm_std_filtered_all = []\n",
    "    # rms_filtered_all = []\n",
    "    # centroid_filtered_all = []\n",
    "    # ellipticity_mean_all=[]\n",
    "\n",
    "    # for imagenumber in range(len(immagini)):\n",
    "    #     data_raw = immagini[imagenumber]\n",
    "    #     data_clean = data_raw\n",
    "    #     poisson_error = np.sqrt(data_raw)\n",
    "    #     background_level = np.median(data_raw)\n",
    "    #     background_error = np.sqrt(background_level)\n",
    "    #     noise = np.sqrt(np.mean(poisson_error**2) + background_error**2)\n",
    "    #     background_estimate = data_raw - noise\n",
    "    #     background_estimate[background_estimate < 0] = 0\n",
    "    #     data = data_raw - background_level\n",
    "    #     data[data < 0] = 0\n",
    "\n",
    "    #     ###########################     SOLO PER 10KHZ ################################################\n",
    "    #     #center_y, center_x = data.shape[0] // 2, data.shape[1] // 2\n",
    "    #     #search_radius = 80  ###per speckle a 3x\n",
    "    #     #y, x = np.ogrid[:data.shape[0], :data.shape[1]]\n",
    "    #     #mask = (x - center_x)**2 + (y - center_y)**2 <= search_radius**2\n",
    "    #     #speckle_coords = np.column_stack(np.where((data > speckle_threshold) & mask))\n",
    "    #     ################################################################################################\n",
    "    #     # QUANDO NON ATTIVO SPECKLE A 10KHZ\n",
    "    #     speckle_coords = np.column_stack(np.where(data > speckle_threshold))\n",
    "    #     real_speckles = []\n",
    "\n",
    "    #     for coord in speckle_coords:\n",
    "    #         y, x = coord\n",
    "    #         max_count = data[y, x]\n",
    "    #         speckle = coord\n",
    "    #         # Check the surrounding pixels within the radius\n",
    "    #         for dy in range(-check_radius, check_radius + 1):\n",
    "    #             for dx in range(-check_radius, check_radius + 1):\n",
    "    #                 ny, nx = y + dy, x + dx\n",
    "    #                 if 0 <= ny < data.shape[0] and 0 <= nx < data.shape[1]:\n",
    "    #                     if data[ny, nx] > max_count:\n",
    "    #                         max_count = data[ny, nx]\n",
    "    #                         speckle = [ny, nx]           \n",
    "    #         if not any(np.array_equal(speckle, x) for x in real_speckles):\n",
    "    #             real_speckles.append(speckle)\n",
    "                \n",
    "    #     real_speckles = np.array(real_speckles)\n",
    "    #     filtered_speckles = []\n",
    "                \n",
    "    #     for speckle in real_speckles:\n",
    "    #         y, x = speckle\n",
    "    #         max_count = data[y, x]\n",
    "    #         keep_speckle = True\n",
    "    #         # Check for speckles that are closer than N pixels\n",
    "    #         for other_speckle in filtered_speckles:\n",
    "    #             distance = np.sqrt((other_speckle[0] - y)**2 + (other_speckle[1] - x)**2)\n",
    "    #             if distance < mindist:   # change here to change the radius (in pixels)\n",
    "    #                 if data[other_speckle[0], other_speckle[1]] > max_count:\n",
    "    #                     keep_speckle = False\n",
    "    #                 else:\n",
    "    #                     filtered_speckles = [fs for fs in filtered_speckles if not np.array_equal(fs, other_speckle)]\n",
    "    #         if keep_speckle:\n",
    "    #             filtered_speckles.append([y, x])\n",
    "\n",
    "    #     filtered_speckles = np.array(filtered_speckles)\n",
    "    #     h, w = data.shape\n",
    "    #     # solo speckle tali che  [y-radius:y+radius+1, x-radius:x+radius+1] stia  dentro l’immagine\n",
    "    #     ys = filtered_speckles[:, 0]\n",
    "    #     xs = filtered_speckles[:, 1]\n",
    "    #     mask = (\n",
    "    #         (ys - radius >= 0) &\n",
    "    #         (ys + radius + 1 <= h) &\n",
    "    #         (xs - radius >= 0) &\n",
    "    #         (xs + radius + 1 <= w)\n",
    "    #     )\n",
    "    #     filtered_speckles = filtered_speckles[mask]\n",
    "    # ###################################à SOLO PER 10KHZ ##############################################  \n",
    "    #     # Calculate the barycenter of the filtered speckles\n",
    "    #     #barycenter_x = filtered_speckles[:, 1].mean()\n",
    "    #     #barycenter_y = filtered_speckles[:, 0].mean()\n",
    "    # # Define a maximum distance from the barycenter to consider a speckle as valid\n",
    "    #     #max_distance = 50  \n",
    "    #     #distances = np.sqrt((filtered_speckles[:, 1] - barycenter_x)**2 + (filtered_speckles[:, 0] - barycenter_y)**2)\n",
    "    #     #filtered_speckles = filtered_speckles[distances <= max_distance] \n",
    "    # #############################################################################\n",
    "\n",
    "       \n",
    "    #     fwhm_single_image, centers = fit_speckle_tot(data, filtered_speckles, radius, speckle_threshold, plate_scale)\n",
    "    #     #print(f\"Number of speckles found in image {imagenumber}: {len(filtered_speckles)}\")\n",
    "        \n",
    "    #     ellipticity_single_image = 1 - np.minimum(fwhm_single_image[:, 0], fwhm_single_image[:, 1]) / np.maximum(fwhm_single_image[:, 0], fwhm_single_image[:, 1])\n",
    "\n",
    "    #     #tutto con indice 1 perché si sta facendo statistica solo sulla X\n",
    "    #     fwhm_x_clipped = sigma_clip(fwhm_single_image[:, 1], sigma=3, maxiters=1)  # o 1 a 3 sigma o 3 a 3.5 sigma\n",
    "    #     fwhm_x_tot_clean = fwhm_single_image[~fwhm_x_clipped.mask]\n",
    "    #     mean_clipped_fwhm = np.mean(fwhm_x_tot_clean[:,1])\n",
    "    #     median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean[:,1])\n",
    "    #     std_clipped_fwhm = np.std(fwhm_x_tot_clean[:,1]) \n",
    "    #     centroid = (np.mean(centers[:,0]), np.mean(centers[:,1])) \n",
    "    #     rms = (np.sqrt(np.mean((centers[:,0] - centroid[0])**2)), np.sqrt(np.mean((centers[:,1] - centroid[1])**2))) \n",
    "    #     # mean_clipped_fwhm = np.mean(fwhm_x_tot_clean)\n",
    "    #     # median_clipped_fwhm = np.ma.median(fwhm_x_tot_clean)\n",
    "    #     # std_clipped_fwhm = np.std(fwhm_x_tot_clean)\n",
    "\n",
    "    #     # Store results for all speckles\n",
    "    #     fwhm_mean_all.append(mean_clipped_fwhm)\n",
    "    #     fwhm_median_all.append(median_clipped_fwhm)\n",
    "    #     fwhm_std_all.append(std_clipped_fwhm)\n",
    "    #     rms_all.append(rms)\n",
    "    #     centroid_all.append(centroid)\n",
    "    #     ellipticity_mean_all.append(np.mean(ellipticity_single_image))\n",
    "        \n",
    "    #     if imagenumber % 500 == 0:\n",
    "    #         prstime = calcProcessTime(start, imagenumber +1 ,len(immagini))\n",
    "    #         print(\"time elapsed: %s s, time left: %s s, estimated finish time: %s\"%prstime)\n",
    "            \n",
    "    # print('Speckles fit done')\n",
    "\n",
    "######################## SPECKLE PSD ######################\n",
    "\n",
    "    print(f'Power Spectra of{file_name}...')\n",
    "    \n",
    "    header = Header()\n",
    "    header['CDELT1'] = 1.0\n",
    "    header['CDELT2'] = 1.0\n",
    "    peak_frequencies = []\n",
    "    peak_powers = []\n",
    "    raw_spectra_all = []\n",
    "    for img in range(len(immagini)):\n",
    "\n",
    "        print(\"processing image \", img ,'/', len(immagini))\n",
    "        largest_peak_freq = 0\n",
    "        largest_peak_power = 0\n",
    "        \n",
    "        #if stacked and i + nstack <= len(immagini):\n",
    "        #    data = np.sum(immagini[i:i + 3], axis=0)\n",
    "        #else:\n",
    "        data = immagini[img]\n",
    "        image_cropped = crop_center(data, crop_size)\n",
    "        data = image_cropped.copy()\n",
    "        background_level = np.median(data)\n",
    "        data = data - background_level\n",
    "        data[data < 0] = 0\n",
    "        image = data.copy()\n",
    "\n",
    "        # Non fitered power spectrum\n",
    "        pspec_raw = PowerSpectrum(image, header=header, distance=1 * u.pc)\n",
    "        pspec_raw.run(verbose=False, xunit=u.pix**-1)\n",
    "        freqs_raw = pspec_raw.freqs.value\n",
    "        psd1D_raw = pspec_raw.ps1D\n",
    "        raw_spectra_all.append({\n",
    "            'file': file_name,\n",
    "            'image_index': img,\n",
    "            'freqs': freqs_raw,\n",
    "            'powers': psd1D_raw\n",
    "        })\n",
    "        \n",
    "        # Apply 2D Butterworth bandpass\n",
    "        filtered_image, mask = butterworth_2d_bandpass(image, lowcut, highcut, ordine)\n",
    "        # Normalize filtered image\n",
    "        filtered_image = np.nan_to_num(filtered_image, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        filtered_image[filtered_image < 0] = 0\n",
    "        filtered_image /= (np.max(filtered_image) + 1e-8)\n",
    "\n",
    "        # Compute power spectrum\n",
    "        pspec_filtered = PowerSpectrum(filtered_image, header=header, distance=1 * u.pc)\n",
    "        pspec_filtered.run(verbose=False, xunit=u.pix**-1)\n",
    "        \n",
    "        freqs = pspec_filtered.freqs.value\n",
    "        ps1D = pspec_filtered.ps1D\n",
    "        largest_peak_freq, largest_peak_power = find_peak_power(freqs, ps1D, expected_speckle_size_pixels, frequency_range)\n",
    "        \n",
    "        peak_frequencies.append(largest_peak_freq)\n",
    "        peak_powers.append(largest_peak_power)\n",
    "\n",
    "        print('peak frequencies:', peak_frequencies)\n",
    "        print('peak powers:', peak_powers)\n",
    "\n",
    "        if largest_peak_freq == 0 and largest_peak_power == 0:\n",
    "             print(\"Could not find any peaks within the specified frequency range.\")\n",
    "        print(f'Power Spectrum of {file_name} done')\n",
    "        \n",
    "############################# SALVATAGGIO RISULTATI ########################################\n",
    "#######################################################################################     \n",
    "\n",
    "    \n",
    "    #centroid_x = [c[1] for c in centroid_all]\n",
    "    #centroid_y = [c[0] for c in centroid_all]\n",
    "    #rms_x = [r[1] for r in rms_all]\n",
    "    #rms_y = [r[0] for r in rms_all]\n",
    "    \n",
    "    data = {\n",
    "    #'FILE':             file_name,\n",
    "    #'FWHM_MEAN':        fwhm_mean_all,\n",
    "    #'FWHM_MEDIAN':      fwhm_median_all,\n",
    "    #'FWHM_STD':         fwhm_std_all,\n",
    "    #'CENTROID_X':       centroid_x,\n",
    "    #'CENTROID_Y':       centroid_y,\n",
    "    #'RMS_X':            rms_x,\n",
    "    #'RMS_Y':            rms_y,\n",
    "    #'MEAN_ELLIPTICITY': ellipticity_mean_all\n",
    "    'PEAK_FREQUENCY':    peak_frequencies,\n",
    "    'PEAK_POWER':        peak_powers,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "    raw_spectra_all_tot.extend(raw_spectra_all)\n",
    "    \n",
    "    ######################## PER FARE TUTTI I RISULTATI IN UN UNICO FILE\n",
    "    #all_dfs.append(df)\n",
    "\n",
    "    del immagini\n",
    "    gc.collect()\n",
    "\n",
    "############### PER TUTTI I RISULTATI IN UN FILE SOLO\n",
    "# Dopo aver processato tutti i file, concatena tutti i DataFrame\n",
    "df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "# Crea la cartella di output (se non esiste)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# Salva CSV unico con tutti i risultati\n",
    "output_csv_all = 'outputs/all_results.csv'\n",
    "df_all.to_csv(output_csv_all, index=False)\n",
    "print(f\"All results saved to CSV file: {output_csv_all}\")\n",
    "# Salva FITS unico con tutti i risultati\n",
    "output_fits_all = 'outputs/all_results.fits'\n",
    "Table.from_pandas(df_all).write(output_fits_all, format='fits', overwrite=True)\n",
    "print(f\"All results saved to FITS table: {output_fits_all}\")\n",
    "\n",
    "\n",
    "\n",
    "rows = []\n",
    "for entry in raw_spectra_all_tot:\n",
    "    fn = entry['file']\n",
    "    idx = entry['image_index']\n",
    "    freqs = entry['freqs']\n",
    "    powers = entry['powers']\n",
    "\n",
    "    df_tmp = pd.DataFrame({\n",
    "        'file': fn,\n",
    "        'image_index': idx,\n",
    "        'frequency': freqs,\n",
    "        'power': powers\n",
    "    })\n",
    "    rows.append(df_tmp)\n",
    "\n",
    "df_long = pd.concat(rows, ignore_index=True)\n",
    "print(f\"Totale righe PSD raw nel df: {len(df_long)}\")\n",
    "\n",
    "csv_path = os.path.join('outputs', 'all_raw_psd.csv')\n",
    "df_long.to_csv(csv_path, index=False)\n",
    "print(f\"Saved raw PSD long CSV to {csv_path}\")\n",
    "\n",
    "# parquet_path = os.path.join('outputs', 'all_raw_psd.parquet')\n",
    "# df_long.to_parquet(parquet_path, index=False)\n",
    "# print(f\"Saved raw PSD parquet to {parquet_path}\")\n",
    "\n",
    "# hdf_path = os.path.join('outputs', 'all_raw_psd.h5')\n",
    "# df_long.to_hdf(hdf_path, key='raw_psd', mode='w')\n",
    "# print(f\"Saved raw PSD HDF5 to {hdf_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
